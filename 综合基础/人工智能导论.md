# 人工智能

## 搜索

- 问题
    - 状态可观察
    - 离散状态
    - 确定性转移
- 树结构
    - 二叉树: 每个节点至多两个分支
    - **搜索树**: 表示搜索的树数据结构
- 状态和节点
    - **状态** 是物理结构的一种表示
    - **节点** 是组成搜索树的一种数据结构
        - 包含父节点, 动作, 状态, 深度, 路径开销, (子节点)
- 通用树搜索
    - 使用初始状态初始化搜索树
    - 循环
        - 如果没有可展开的节点则失败
        - 依据 **策略** 选择一个叶节点用于展开
            - 展开创建了新节点并填入了相应的字段
            - 搜索的关键: 注重一个可行选项, 将其他选项放到一边
            - 所有搜索算法有着相同的结构, 不同之处在于选择叶节点的策略
        - 如果该节点达到了目标, 则结束搜索
        - 展开节点并加入搜索树
- 存储数据结构: 栈和队列
- 内存空间: 栈空间和堆空间
- 深度优先搜索
    - 使用栈的 DFS: 有栈溢出的风险
    - 使用堆的 DFS: 使用 `fringe` 表示边界, 存储的是 **节点**, 使用 `REMOVE-FRONT` 取出
- 图搜索
    - 在树搜索的基础上加入 `closed` 来标识已访问过的 **状态** (非节点)
    - 在 `GOAL-TEST` 后进行判断
- 搜索策略
    - 策略决定了展开的次序
    - 策略评估维度
        - 完全性: 如果解存在, 是否总能找到一个解
        - 时间复杂度: 展开的节点个数
        - 空间复杂度: 内存中最大的节点个数
        - 最优性: 是否总能找到最小开销解 (最优解)
    - 时间复杂度与空间复杂度策略所用术语
        - `b`: 搜索树的最大分支因子
        - `d`: 最优解的深度
        - `m`: 状态空间的最大深度 (可能达到无穷)
- 无信息搜索
    - 广度优先搜索 (Breadth-first search, BFS)
    - 一致代价搜索 (Uniform-cost search, UCS)
    - 深度优先搜索 (Depth-first search, DFS)
    - 深度有限搜索 (Depth-limited search, DLS)
    - 迭代加深搜索 (Iterative deepening search, IDS)
- 广度优先搜索
    - 展开最浅层的未展开节点
    - `fringe` 是 FIFO 队列, 即新后继节点放于末端
    - 性质
        - 完全性: Yes (当 `b` 有限时)
        - 时间复杂度: $1 + b + b^{2} + \cdots + b^{d} + b(b^{d} - 1) = O(b^{d + 1})$
        - 空间复杂度: $O(b^{d+1})$ (每个节点均在内存中)
        - 最优性: Yes (当 `cost = 1` 时)
        - 空间复杂度是个大问题
- 深度优先搜索
    - 展开最深层的的未展开节点
    - `fringe` 是 LIFO 队列, 即新后继节点放于首部
    - 性质
        - 完全性: No (在无限深度的空间中失败, 或者可能存在环)
        - 时间复杂度: $O(b^{m})$ (如果 `m` 远大于 `d` 会显得非常糟糕, 但是如果解是稠密的, 则可能会比 BFS 快得多)
        - 空间复杂度: $O(bm)$ (线性空间!)
        - 最优性: No
- 一致代价搜索
    - `fringe` 是优先级队列, 总是取出最小 **路径开销** 的节点
    - 性质
        - 完全性: Yes (当单步开销 $\ge \epsilon$)
        - 时间复杂度: $O(b^{\lceil C^{*} / \epsilon \rceil})$ (其中 $C^{*}$ 是最优解的路径开销)
        - 空间复杂度: $O(b^{\lceil C^{*} / \epsilon \rceil})$
        - 最优性: Yes
            - 因为优先级队列总是会取出最小路径开销的节点用于展开
            - 最优路径上的目标状态有着相较于其他次优路径更小的路径开销
            - 在展开最优路径上的目标状态前绝不会在任何次优路径上展开目标状态
        - 关键点就在于最优路径上的目标状态有着更小的路径开销
- 深度有限搜索
    - 使用 `limit` 限制了 DFS 的最深深度
- 迭代加深搜索
    - 用逐渐加深的 `limit` 进行深度有限搜索
    - 每一次搜索都从头开始
    - 性质
        - 完全性: Yes
        - 时间复杂度: $O(b^{d})$
        - 空间复杂度: $O(bd)$
        - 最优性: Yes (当 `cost = 1` 时)
- 总结
    | 标准       | 广度优先搜索 | 一致代价搜索                            | 深度优先搜索 | 深度有限搜索      | 迭代加深搜索 |
    | ---------- | ------------ | --------------------------------------- | ------------ | ----------------- | ------------ |
    | 完全性     | Yes*         | Yes*                                    | No           | Yes, if $l \ge d$ | Yes          |
    | 时间复杂度 | $b^{d+1}$    | $O(b^{\lceil C^{*} / \epsilon \rceil})$ | $b^{m}$      | $b^{l}$           | $b^{d}$      |
    | 空间复杂度 | $b^{d+1}$    | $O(b^{\lceil C^{*} / \epsilon \rceil})$ | $bm$         | $bl$              | $bd$         |
    | 最优性     | Yes*         | Yes                                     | No           | No                | Yes          |
- 有信息搜索 (启发式搜索)
    - 最佳优先搜索 $f$
        - 什么是最佳
    - 一致开销搜索
        - 开销函数 $g$ 与启发函数 $h$ 则有 $g(n) + h(n)$
- 贪婪搜索
    - 评估函数 $f(n) = h(n)$ 用于估计从 $n$ 到最近目标的开销
    - 常见的有直线距离等
    - 贪婪搜索总是展开似乎离目标最近的节点 (最小 $h(n)$)
    - 性质
        - 完全性: No (可能会陷入循环, 必须得有重复状态检测)
        - 时间复杂度: $O(b^{m})$ (但是好的启发函数可以得到极高的改进)
        - 空间复杂度: $O(b^{m})$
        - 最优性: No
- A* 搜索
    - Idea: 避免展开已知的昂贵节点
    - 评估函数: $f(n) = g(n) + h(n)$
        - $g(n)$ 为到达 $n$ 的路径开销
        - $h(n)$ 为估计的从 $n$ 到目标的路径开销
        - $f(n)$ 为估计的经过 $n$ 到达目标的路径开销
    - 可容性 (Admissible): $0 \le h(n) \le h^{*}(n)$, 即不会高估
        - 假设 $A$ 为最优目标节点, $B$ 为次优目标节点, $n$ 为 $A$ 的一个祖先节点
        - $f(n) = g(n) + h(n) \le g(n) + h^{*}(n) = g(A) = g(A) + h(A) < g(B) < g(B) + h(B)$
        - 因此 $A$ 的所有祖先节点都会在 $B$ 之前被展开
        - 即可推得 $A$ 会在 $B$ 之前被展开
        - 在树搜索上最优, 但是在图搜索上就不再是最优的了
            - 因为可容性只能保证一定到达最近的目标状态
            - 不能保证使用了最优路径到达最近的目标状态
            - 因为可能会有中间节点估计开销比较高
            - 因此 $g(n) + h(n)$ 存在递减现象
            - 导致错过了最优路径
    - 一致性 (Consistent): $h(n) \le c(n, a', n') + h(n')$, 其中 $n'$ 为 $n$ 经过动作 $a'$ 到达 $n'$ 的节点
        - 一致性可以推导出可容性, 只需要递推地推导即可得到这个结论
        - 断言: $g(n) + h(n)$ 沿着任何路径都是非递减的
        - $g(n') + h(n') = g(n) + c(n, a', n') + h(n') \ge g(n) + h(n)$
        - 断言: 在目标节点 $n$ 被展开时, 到达目标节点的最优路径已经被展开了
        - 假设最优路径上节点 $n'$ 对应的目标节点为 $n^{*}$
        - $g(n') + h(n') \le g(n^{*}) + h(n^{*}) < g(n) + h(n)$
        - 因此 $n'$ 一定会在 $n$ 之前展开 (注意这里的 $n^{*}$ 和 $n$ 可能为同一个状态)
    - 令 $h(n) = 0$, 满足一致性, 退化为一致开销搜索
- **对手搜索**
    - 效用函数 `UTILITY(s, p)`, 也叫目标函数或者结算函数
- 最小最大化算法
    - 返回能够最大化 `MIN-VALUE(RESULT(a, state))` 的 `a`
    - `MIN-VALUE` 的计算方法为取 `MAX-VALUE(s)` 的最小值
    - `MAX-VALUE` 的计算方法为取 `MIN-VALUE(s)` 的最大值
    - 性质
        - 完全性: Yes (因为树有限)
        - 最优性: Yes (当面对同样最优的对手时)
        - 时间复杂度: $O(b^{m})$
        - 空间复杂度: $O(bm)$ (深度优先搜索)
- Alpha-Beta 剪枝
    - 在 `MAX-VALUE` 后加入 `if v >= beta then return v` 以及 `alpha = max(alpha, v)`
        - 因为此时 `v` 已经达到了上界 (足够大了), 在父函数处不会被选中
        - 下界可以更新为已探索分支的最大值, 因为后续分支再小也不会选中了
    - 在 `MIN-VALUE` 后加入 `if v <= alpha then return v` 以及 `beta = min(beta, v)`
        - 因为此时 `v` 已经达到了下界 (足够小了), 在父函数处不会被选中
        - 上界可以更新为已探索分支的最小值, 因为后续分支再大也不会选中了
    - https://oi-wiki.org/search/alpha-beta/
- 资源限制
    - 使用 `CUTOFF-TEST` 而不是 `TERMINAL-TEST`
        - 深度限制
        - 或者加入静止搜索 (quiescence search), 使用某个标准区分静止位置和波动位置
    - 使用 `EVAL` 而不是 `UTILITY`
        - 评估函数用于估计当前状态的好坏
    - 进而得到 `H-Minimax` 算法
- 随机游戏
    - 加入一个 `CHANCE` 玩家, 模拟随机状态转移, 使用全概率公式
- 多臂老虎机
    - 每个臂都有期望奖赏, 但是期望奖赏未知, 且奖赏分布也未知
    - 在固定次数尝试中最大化总奖赏
    - $T$ 次尝试和 $K$ 个臂
    - 最简单的策略
        - 仅探索: 每个臂尝试 $T / K$ 次
        - 仅利用: 每个臂尝试一次, 然后总是选择奖赏最高的那一个臂
    - $\epsilon$-贪心
        - $\epsilon$ 概率尝试一个随机臂
        - $1-\epsilon$ 概率尝试最佳的臂
        - 用 $\displaystyle Q(k) = \frac{Q(k) \times \operatorname{count}(k) + v}{\operatorname{count}(k) + 1}$ 来在线计算每个臂的期望奖赏
    - Softmax
        - 以概率 $\displaystyle P(k) = \frac{\exp(\frac{Q(k)}{\tau})}{\sum_{i=1}^{K} \exp(\frac{Q(i)}{\tau})}$ 来选取臂, 其中 $\tau$ 用于控制平衡
    - 上置信界 (Upper-confidence bound, UCB)
        - 选择有最大值的臂
        - $\displaystyle Q(k) + \sqrt{\frac{2 \ln n}{n_k}}$
    - MCTS (UCT)
        - 选择 (Selection)
            - 三类节点
                - 未访问: 还没有评估过当前局面
                - 未完全展开: 被评估过至少一次, 但是子节点 (下一步的局面) 没有被全部访问过, **可以进一步扩展**
                - 完全展开: 子节点被全部访问过
            - 我们找到 **目前认为**「最有可能会走到的」一个未被评估的局面 (双方都很聪明的情况下), 并且 **选择** 它
            - $\displaystyle \operatorname{UCT}(v_i, v) = \frac{Q(v_i)}{N(v_i)} + c\sqrt{\frac{\log(N(v))}{N(v_i)}}$
        - 扩展 (expansion)
            - 将刚刚选择的节点加上一个统计信息为「0/0」的节点
        - 模拟 (Simulation)
            - 快速走子 (Rollout)
        - 回溯 (Backpropagation)
            - 回溯, 沿途更新各个父节点的统计信息
    - 性质
        - 最优: Yes (无限次之后)
        - 不需要启发函数
    - 优化
        - 可以优化 Rollout 部分
- 通用解空间搜索
    - 贪心算法
        - 对连续空间进行离散化
        - 爬山搜索: 有时也被称作贪婪局部搜索
            - 会不断往高处的邻居节点走去
            - 在三种情况下经常被困: 局部最大值, 山岭, 高原
        - 单纯随机搜索算法: 在无限步之后时全局最优的
        - 前者注重利用, 后者注重探索
    - 元启发式算法
        - 问题独立, 黑箱, 零阶优化 (不需要梯度信息)
        - 常常从自然现象中获得灵感
    - 模拟退火算法
        - Idea: 通过允许一些 "坏" 的移动来逃离局部最大值, 但是会逐渐地减少大小和频次
        - 接收 `problem` 和 `schedule`, 后者将时间 `t` 映射到温度 `temperature`
        - 在 `current` 附近的与 `T` 大小正相关的范围内随机取一个节点
        - 通过 `DeltaE = Value(next) - Value(current)` 得到 $\Delta E$
        - 如果 $\Delta E > 0$ 则接受, 否则以 $e^{\Delta E / T}$ 的概率接受
        - 以下关于模拟退火算法陈述正确的是:
            - 模拟退火算法不是选择最佳行动, 而是选择随机行动
            - 模拟退火算法的内循环与爬山法相似
    - 局部束搜索
        - 保留 k 个状态而非 1 个状态
        - 为了避免 k 个状态都停留在同一个局部最高峰, 可以随机选择 k 个后继节点
    - 遗传算法
        - 遗传算法是随机束搜索的一个变体, 其中后继节点的生成是由组合两个双亲状态, 而不是修改单一状态
        - 步骤
            - 随机初始化, 得到父代群体
            - 循环
                - 繁殖, 得到后代解
                    - 突变, 杂交
                - 评估, 得到已评估后代解
                - 选择, 得到父代群体
    - 元启发式搜索性质
        - 零阶: 不需要梯度信息
        - 收敛: 如果有 $P(x^{*}|x) > 0$ 或 $P(x \to x_1 \to \cdots \to x_k \to x^{*}) > 0$, 可以找到最优解
- 约束满足问题 (CSP)
    - 例如地图着色问题
    - 回溯搜索
        - 类似于 DFS, 但是是对边/路径进行递归
        - 使用一个 `assignment` 来记录当前考虑的路径
        - 回溯法是无信息的, 我们可以让它更有信息以提速
            - 通用方法:
            - 该选择哪个变量
            - 为变量赋各种值的次序
            - 如何更早检测到不可避免的失败
            - 通过问题结构进行优化
    - 最小剩余值 (MRV): 选择拥有最少合法值的变量
    - 度启发: 选择拥有最多限制的变量
    - 最小限制值 (LCV): 给定一个变量, 选择减少最少其他变量可行值的哪个值
    - 前向检查: **为未赋值变量持续记录剩余的合法值, 当没有任何的合法值时就终止**
        - 缺点: 只关注了已赋值变量和未赋值变量之间的约束, 没有考虑未赋值变量内部之间的约束, 因此并没能检测到所有失败
    - 约束传播: 
        - 在前向检查的基础上, 约束传播重复地使用所有约束进行限制
    - 弧一致
        - $X \to Y$ 一致当且仅当 $X$ 中的每个值 $x$ 均有 $y \in Y$ 与其一致
        - 如果 $X$ 失去了一个值, 那么 $X$ 的邻居均要重新检查
        - 时间复杂度 $O(n^{2} d^{3})$, 可以被减少到 $O(n^{2} d^{2})$
    - 对于树结构
        - 选择一个根节点, 进行拓扑排序, 依次不断去除不一致节点
        - 时间复杂度为 $O(n d^{2})$, 而通用的图则为 $O(d^{n})$
    - 对于接近树的结构
        - 切集: 删去切集中的节点之后, 图会变为一棵树
        - **设切集大小为 $c$, 则时间复杂度为 $O(d^{c} \cdot (n - c) d^{2})$, 在较小的 $c$ 时有极快的速度**
    - CSP 的迭代算法
        - **爬山算法, 模拟退火算法常常只能工作中所有变量均被赋值的完全状态上**
        - 为了应用到 CSP 上, 我们可以允许不满足约束的状态存在
        - 变量选择: 随机选择任何冲突变量
        - 值选择: 最小化冲突启发, 选择违背了最少约束的值


## 知识

- 逻辑概论 (PL)
    - 逻辑是用于表示知识以推导出结论的形式语言
    - 语法定义了语言中的句子的结构
    - 语义定义了句子的意义, 也即句子相对于模型的真值
- 蕴含
    - $KB \models \alpha$
    - 知识库 KB 蕴含句子 $\alpha$ 当且仅当 $\alpha$ 在所有 $KB$ 为真的世界中均为真
- 模型
    - 模型是形式化地结构定义的世界, 在其中能够评估真值
    - 我们说 $m$ 是 $\alpha$ 的一个模型, 当 $\alpha$ 在 $m$ 中为真时
    - $M(\alpha)$ 是 $\alpha$ 的所有模型组成的集合
    - $KB \models \alpha$ 当且仅当 $M(KB) \subseteq M(\alpha)$
- Wumpus 模型
    - KB = 世界规则 + 观察
    - 对应一个 KB 会有多个可能的模型
    - $\alpha_1 = $ "[1, 2] 位置安全" 可以通过模型检测来证明 $KB \models \alpha_1$
- 推断
    - $KB \vdash_{i} \alpha$ 表示 $\alpha$ 可以通过过程 $i$ 从 $KB$ 中得到
    - 可靠性: $i$ 是可靠的, 当任何 $KB \vdash_{i} \alpha$ 均有 $KB \models \alpha$
    - 完全性: $i$ 是完全的, 当任何 $KB \models \alpha$ 均有 $KB \vdash_{i} \alpha$
- 命题逻辑
    - $\lnot, \land, \lor, \to, \leftrightarrow$
    - 通过 DFS 枚举真值表来推断: 检查 $KB$ 为真的行, $\alpha$ 是否也为真
        - 时间复杂度 $O(2^{n})$, 是 co-NP-complete 问题
    - 逻辑运算定律
        - 交换律, 结合律, 分配律, 双重否定律, 幂等律
        - 德摩根律: $\lnot (A \lor B) \Leftrightarrow \lnot A \land \lnot B, \lnot (A \land B) \Leftrightarrow \lnot A \lor \lnot B$
        - 蕴含等值式: $A \to B \Leftrightarrow \lnot A \lor B$
        - 假言易位: $A \to B \Leftrightarrow \lnot B \to \lnot A$
    - 有效性和可满足性
        - 一个句子是有效的当且仅当其在所有模型中均为真
        - $KB \models \alpha$ 当且仅当 $KB \to \alpha$ 是有效的
        - 一个句子是可满足的当且仅当存在模型使其为真
        - $KB \models \alpha$ 当且仅当 $KB \land \lnot \alpha$ 是不可满足的
            - 也即是使用归谬法 (反证法)
    - 证明方法可以直接分成两大类
        - 使用推断规则进行证明, 即从语法上证明, 再通过可靠性得到结果
            - 应用一系列的推断规则, 可以将推断规则视为标准搜索算法里面的操作符
            - 常常要把句子翻译到标准形式
        - 模型检测, 即从语义上证明
            - 直接使用真值表枚举
            - 使用回溯法进行加速
            - 在模型空间内进行启发式搜索 (可靠, 但是不完全)
    - 前向推理
        - Idea: 触发所有前提在 KB 中满足的规则, 并将结论加入 KB 中, 直到 query 被发现
        - 需要用到 Horn 形式的 Horn 从句, 也即符号, 或者符号合取式到符号的蕴含式
        - 可以在线性时间内完成
        - 输入 `KB` 和 `q`, 局部变量
            - `count`: 通过 `count[c]` 来判断从句 `c` 的前提条件是否已经被满足 (因为每个符号只会被推断一遍, 所以可以用 count 来判断)
            - `inferred`: 用 `inferred[p]` 记录当前符号 `p` 是否已经被推断过, 如果是则跳过
            - `agenda`: 当前议程, 也就是下一步要进行推断的符号的列表
    - 后向推理
        - Idea: 从 `q` 开始, 为了证明 `q`, 检查是否 `q` 已知, 或者通过后向推理递归地证明存在某些可以推出 `q` 的规则的所有前提均已知
        - 避免循环: 检查是否子目标已经在目标栈里了
        - 动态规划: 检查是否子目标已证明为真, 或者已经失败了
    - 比较
        - **前向推理是数据驱动的, 自动化的, 无意识的过程**
            - 目标识别, 路径规划
        - 但是仍然有很多任务是和目标相关的
        - **后向推理是目标驱动的, 适合问题求解**
        - **后向推理的时间复杂度往往比前向推理要低** (也即是低于 KB 的大小)
    - 消解
        - 合取范式 CNF: 由一系列由文字组成的析取式 (从句) 组成的合取式
            - 例如 $(A \lor \lnot B) \land (B \lor \lnot C \lor \lnot D)$
        - 消解规则: 例如 $(A \lor B, \lnot B) \Rightarrow A$
            - 在命题逻辑中是可靠且完全的
        - 转换成 CNF
            - 消除 $\leftrightarrow$: 将 $\alpha \leftrightarrow \beta$ 替换成 $(\alpha \to \beta) \land (\beta \to \alpha)$
            - 消除 $\to$: 将 $\alpha \to \beta$ 替换成 $\lnot \alpha \lor \beta$
            - 使用德摩根律将 $\lnot$ 移动至括号内部, 并消除双重否定
            - 使用分配律将最终结果展开成 CNF
        - 消解算法
            - 通过矛盾来证明, 例如证明 $KB \land \lnot \alpha$ 是不可满足的
            - 不断循环地组合两个任意从句并消解, 然后加入从句集合中
                - 如果其中出现了空从句, 则返回 True
                - 如果从句集合稳定不再变化, 则返回 False
    - 可满足问题
        - 命题逻辑 CNF
        - 找到一个赋值以满足从句的合取式为真, 或者证明其不可满足
            - 文字: $x_1, x_2, \ldots, x_n$
            - $(x_1 \lor x_2) \land (\lnot x_2 \lor x_3)$
        - 2SAT: 每个从句至多两个文字
            - P-solvable
        - 3SAT: 每个从句至多三个文字
            - NP-hard
        - 如果所有 NP 问题都可以多项式归约到问题 A, 那么问题 A 就是 NP-Hard; 如果问题 A 既是 NP-Hard 又是 NP, 那么它就是 NP-Complete. 从定义我们很容易看出, NP-Hard 问题类包含了 NP- Complete 类. 但进一步的我们会问, 是否有属于 NP-Hard 但不属于 NP-Complete 的问题呢? 答案是肯定的. 例如停机问题, 也即给出一个程序和输入, 判定它的运行是否会终止. 
        - 怎样证明一个问题 C 是 NP 完全问题呢? 首先, 要证明 C 是 NP 问题, 也就是 C 的解的正确性容易验证; 然后要证明有一个 NP 完全问题 B, 能够在多项式时间内归约到 C. 这就要求必须先存在至少一个 NPC 问题.
        - SAT 求解程序
            - DPLL: 带有启发函数的深度优先搜索
            - WalkSAT: 局部搜索的爬山算法, 失败时并不代表不可满足
    - 优点
        - 命题逻辑是陈述性的, 也即语法是基于事实的
        - 命题逻辑支持部分的, 析取, 取反信息
        - 命题逻辑是组合式的
        - 命题逻辑是上下文独立的
    - 缺点
        - 表达能力不足
- 一阶逻辑 (FOL)
    - 包含元素: 常量, 谓词, 函数, 变量, 连接符, 相等, 量词
    - 原子语句
        - 原子语句 = 谓词(项, ..., 项) 或 项 = 项
        - 项 = 函数(项, ..., 项) 或 常量 或 变量
    - 复杂语句: 从原子语句开始使用连接符连接得到的句子
    - 真值
        - 句子为真是相对于一个模型和一个解释
        - 模型包含了领域元素和它们之间的关系
        - 解释将常量映射到对象, 将谓词映射到关系, 将函数映射到函数关系
        - 一个原子句子为真, 当且仅当它的项对应的对象组成的组合在谓词对应的关系集合里
    - 全称量词, 存在量词
        - 全称量词一般使用 $\forall x (P(x) \to Q(x))$ 的格式
        - 存在量词一般使用 $\exists x (P(x) \land Q(x))$ 的格式
        - $\forall x \forall y \equiv \forall y \forall x, \exists x \exists y \equiv \exists y \exists x$
        - $\exists x \forall y \not\equiv \forall y \exists x$
        - 对偶性: $\forall x P(x) \equiv \lnot \exists x \lnot P(x), \exists x P(x) \equiv \lnot \forall x \lnot P(x)$
    - 和 FOL 交互
        - 替换: $\sigma$ 将变量映射到一个对象, 称作替换, 加上句子记作 $S \alpha$
        - $Ask(KB, S)$ 返回某些或全部满足 $KB \models S\sigma$ 的替换 $\sigma$


## 贝叶斯网

- 在不确定性下做决策
    - 效用理论用于表示和推理偏好
    - 决策理论 = 效用理论 + 概率理论
- 概率论基础, 随机变量
- 命题: 将一个命题看作一个事件, 即样本点的集合
    - 给定布尔随机变量 $A$, 可以将 $A = true$ 事件简写成 $a$
    - 同理有简写 $a \land \lnot b$ 等
- 条件概率链: $P(X_1, \ldots, X_n) = \prod_{i=1}^{n} P(X_i|X_1, \ldots, X_{i-1})$
- 枚举推断
    - $P(Y|E=e) = \alpha P(Y,E=e) = \alpha \sum_{h} P(Y, E=e, H=h)$
    - 时间复杂度 $O(d^{n})$ 极大
- 独立性, 条件独立性
    - 条件独立性: $P(a|b,c) = P(a|c)$, 即给定 $c$, $a$ 条件独立于 $b$
- 贝叶斯公式: $\displaystyle P(a|b) = \frac{P(b|a)P(a)}{P(b)}$
- 贝叶斯网
    - 每一个变量一个节点
    - 有向无环图 (箭头代表 "直接影响")
    - 每个节点给定它的父节点后的条件分布 $P(X_i|Parents(X_i))$
        - 最简单的情况, 可以表示成一个条件概率表 (CPT)
        - 这里我们一般讨论布尔变量
- 紧致性
    - 使用条件概率表 CPT 的空间复杂度是 $O(n \cdot 2^{k})$, 其中 $k$ 为最大父节点数
    - 随着 $n$ 线性增大, 小于 $O(2^{n})$ 的全连接表
- 全局语义
    - **全局语义为全连接分布, 也即所有局部条件分布的乘积**
    - $P(x_1, \ldots, x_n) = \prod_{i=1}^{n} P(x_i|parents(X_i))$
- 局部语义
    - **每一个节点在给定所有父节点的情况下, 均条件独立于它的非后代节点**
- 马尔可夫毯
    - **每个节点在给定它的马尔可夫毯的情况下, 均条件独立于其他所有节点**
    - **马尔可夫毯: 父节点 + 子节点 + 子节点的父节点**
- 精确推断
    - 枚举推断
        - 空间复杂度 $O(n)$, 事件复杂度 $O(d^{n})$
    - 变量消去
        - 具体看西瓜书
    - 精确推断的复杂度
        - 对于多树 (polytree)
            - 在图论中, 多树是有向无环图, 其底层无向图是树. 换句话说, 如果我们将其有向边替换为无向边, 那么我们将获得一个连接且非循环的无向图.
            - 时间复杂度为 $O(d^{k} n)$
        - 对于非多树
            - 可以将 3SAT 规约为精确推断问题 (NP-hard)
            - 等价于去计 3SAT 模型数 (NP-complete)
- 近似推断
    - 拒绝采样
    - MCMC
    - 马尔可夫毯采样

