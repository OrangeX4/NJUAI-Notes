{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37662482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一些全局配置\n",
    "config = {\n",
    "    'is_train': False,  # 是否进行训练\n",
    "    'is_save': False,  # 是否保存模型文件\n",
    "    'is_load': True,  # 是否加载模型文件\n",
    "    'is_save_result': True,  # 是否保存结果\n",
    "\n",
    "    # 路径相关配置\n",
    "    'cwd': '.',  # 工作路径\n",
    "    'model_path': '/models/rnn.pth',  # 模型保存路径\n",
    "    'result_data': '/data/result.txt',  # 结果保存路径\n",
    "    'train_data': '/data/train_preprocessed.json',  # 训练数据\n",
    "    'test_data': '/data/test_preprocessed.json',  # 测试数据\n",
    "    'word_vectors': '/data/word_vectors_filtered.txt',  # 词向量\n",
    "\n",
    "    # 训练数据划分相关配置\n",
    "    'random_seed': 42,  # 随机种子\n",
    "    'train_set_ratio': 0.9,  # 训练集占训练数据的比重\n",
    "    'batch_size': 64,  # 训练批次\n",
    "    'num_steps': 80,  # 填充\n",
    "\n",
    "    # Model 相关配置\n",
    "    'embed_size': 100,  # 嵌入层 size\n",
    "    'num_hiddens': 120,\n",
    "    'num_layers': 2,\n",
    "    'h': lambda x: 1 / x ** 2,\n",
    "    # 'dropout': 0.5,\n",
    "\n",
    "    # 训练相关配置\n",
    "    'lr': 0.01,\n",
    "    'num_epochs': 15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb99f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当前是否是 google colab 中\n",
    "is_colab = True\n",
    "try:\n",
    "    from google.colab import drive\n",
    "except ImportError:\n",
    "    is_colab = False\n",
    "# 挂载 google drive\n",
    "if is_colab:\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# 为 Colab 更改对应配置\n",
    "if is_colab:\n",
    "    config = {\n",
    "        **config,\n",
    "        'is_train': True,\n",
    "        'is_save': True,\n",
    "        'is_load': False,\n",
    "        'cwd': '/content/drive/MyDrive/Colab Notebooks/nlp-target-sentiment-analysis',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a60484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为 Colab 安装对应依赖\n",
    "if 'is_init' not in locals().keys() and is_colab:\n",
    "    !pip install torch==1.12.0\n",
    "    !pip install torchvision==0.13.0\n",
    "    !pip insatll matplotlib==3.0\n",
    "    !pip install matplotlib_inline==0.1.6\n",
    "is_init = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda92028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:11.836447Z",
     "iopub.status.busy": "2022-12-07T17:01:11.835782Z",
     "iopub.status.idle": "2022-12-07T17:01:47.028237Z",
     "shell.execute_reply": "2022-12-07T17:01:47.027324Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f0b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\n",
    "\n",
    "    Defined in :numref:`sec_use_gpu`\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gpus():\n",
    "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\n",
    "\n",
    "    Defined in :numref:`sec_use_gpu`\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "             for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"Truncate or pad sequences.\n",
    "\n",
    "    Defined in :numref:`sec_machine_translation`\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # Truncate\n",
    "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
    "\n",
    "class Accumulator:\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "numpy = lambda x, *args, **kwargs: x.detach().numpy(*args, **kwargs)\n",
    "size = lambda x, *args, **kwargs: x.numel(*args, **kwargs)\n",
    "reshape = lambda x, *args, **kwargs: x.reshape(*args, **kwargs)\n",
    "to = lambda x, *args, **kwargs: x.to(*args, **kwargs)\n",
    "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
    "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\n",
    "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\n",
    "transpose = lambda x, *args, **kwargs: x.t(*args, **kwargs)\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    \"\"\"Compute the number of correct predictions.\n",
    "\n",
    "    Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = argmax(y_hat, axis=1)\n",
    "    cmp = astype(y_hat, y.dtype) == y\n",
    "    return float(reduce_sum(astype(cmp, y.dtype)))\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Defined in :numref:`subsec_linear_model`\"\"\"\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"Return the average time.\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"Return the sum of time.\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"Return the accumulated time.\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    \"\"\"Set the axes for matplotlib.\n",
    "\n",
    "    Defined in :numref:`sec_calculus`\"\"\"\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    if legend:\n",
    "        axes.legend(legend)\n",
    "    axes.grid()\n",
    "\n",
    "class Animator:\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        # use_svg_display()\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # Use a lambda function to capture arguments\n",
    "        self.config_axes = lambda: set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    \"\"\"Compute the accuracy for a model on a dataset using a GPU.\n",
    "\n",
    "    Defined in :numref:`sec_lenet`\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # No. of correct predictions, no. of predictions\n",
    "    metric = Accumulator(2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # Required for BERT Fine-tuning (to be covered later)\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(accuracy(net(X), y), size(y))\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def count_corpus(tokens):\n",
    "    \"\"\"Count token frequencies.\n",
    "\n",
    "    Defined in :numref:`sec_text_preprocessing`\"\"\"\n",
    "    # Here `tokens` is a 1D list or 2D list\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # Flatten a list of token lists into a list of tokens\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"Vocabulary for text.\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        \"\"\"Defined in :numref:`sec_text_preprocessing`\"\"\"\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # Sort according to frequencies\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # The index for the unknown token is 0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # Index for the unknown token\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):  # Index for the unknown token\n",
    "        return self._token_freqs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1e1136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     random.seed(seed)\n",
    "    #  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 设置随机数种子\n",
    "setup_seed(config['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b4ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIter:\n",
    "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
    "\n",
    "    def __init__(self, data_arrays, batch_size) -> None:\n",
    "        self.features, self.labels = data_arrays\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Return the batch iterator and switch to the next epoch.\"\"\"\n",
    "        # 通过yield返回一个迭代器对象\n",
    "        for i in range(0, len(self.features), self.batch_size):\n",
    "            yield (self.features[i: i + self.batch_size], self.labels[i: i + self.batch_size])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of batches.\"\"\"\n",
    "        return len(self.features) // self.batch_size\n",
    "\n",
    "\n",
    "def load_data(batch_size, num_steps=80):\n",
    "    with open(config['cwd'] + config['train_data'], 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    # 分出一部分训练数据作为验证集\n",
    "    random.shuffle(train_data)\n",
    "    test_data = train_data[:int(len(train_data) * (1 - config['train_set_ratio']))]\n",
    "    train_data = train_data[int(len(train_data) * (1 - config['train_set_ratio'])):]\n",
    "    train_tokens = [data['tokens'] for data in train_data]\n",
    "    test_tokens = [data['tokens'] for data in test_data]\n",
    "    train_dist = [data['dist'][1:] for data in train_data]\n",
    "    test_dist = [data['dist'][1:] for data in test_data]\n",
    "    # train_dist = [[1] * len(data['tokens']) for data in train_data]\n",
    "    # test_dist = [[1] * len(data['tokens']) for data in test_data]\n",
    "    train_labels = [int(data['label']) + 1 for data in train_data]\n",
    "    test_labels = [int(data['label']) + 1 for data in test_data]\n",
    "    vocab = Vocab(train_tokens, min_freq=5)\n",
    "    train_features = torch.tensor([truncate_pad(\n",
    "        vocab[train_tokens[i]], num_steps, vocab['<pad>']) + truncate_pad(\n",
    "        train_dist[i], num_steps, 100) for i in range(len(train_tokens))])\n",
    "    test_features = torch.tensor([truncate_pad(\n",
    "        vocab[test_tokens[i]], num_steps, vocab['<pad>']) + truncate_pad(\n",
    "        test_dist[i], num_steps, 100) for i in range(len(test_tokens))])\n",
    "    train_iter = DataIter((train_features, torch.tensor(train_labels)),\n",
    "                                batch_size)\n",
    "    test_iter = DataIter((test_features, torch.tensor(test_labels)),\n",
    "                               batch_size)\n",
    "    return train_iter, test_iter, vocab\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "num_steps = config['num_steps']\n",
    "train_iter, test_iter, vocab = load_data(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c48de0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:47.032557Z",
     "iopub.status.busy": "2022-12-07T17:01:47.031881Z",
     "iopub.status.idle": "2022-12-07T17:01:47.038872Z",
     "shell.execute_reply": "2022-12-07T17:01:47.038084Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens,\n",
    "                 num_layers, h=lambda x: 1 / x ** 2, **kwargs):\n",
    "        super(BiRNN, self).__init__(**kwargs)\n",
    "        self.h = h\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # 将bidirectional设置为True以获取双向循环神经网络\n",
    "        self.encoder = nn.LSTM(embed_size, num_hiddens, num_layers=num_layers,\n",
    "                                bidirectional=True)\n",
    "        self.decoder = nn.Linear(4 * num_hiddens, 3)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs的形状是（批量大小，时间步数）\n",
    "        # 因为长短期记忆网络要求其输入的第一个维度是时间维，\n",
    "        # 所以在获得词元表示之前，输入会被转置。\n",
    "        # 输出形状为（时间步数，批量大小，词向量维度）\n",
    "        # 一半作为 inputs, 一半作为 dist\n",
    "        shape = inputs.shape\n",
    "        dist = inputs[:, shape[1]//2:]\n",
    "        inputs = inputs[:, :shape[1]//2]\n",
    "        # 通过 self.h 处理得到 weights\n",
    "        weights = self.h(dist)\n",
    "        embeddings = self.embedding(inputs.T)\n",
    "        # 通过 weights 乘上 embeddings 得到加权后的 embeddings\n",
    "        weights = weights.T\n",
    "        weights = weights.reshape(weights.shape[0], weights.shape[1], 1)\n",
    "        embeddings = embeddings * weights\n",
    "        self.encoder.flatten_parameters()\n",
    "        # 返回上一个隐藏层在不同时间步的隐状态，\n",
    "        # outputs的形状是（时间步数，批量大小，2*隐藏单元数）\n",
    "        outputs, _ = self.encoder(embeddings)\n",
    "        # 连结初始和最终时间步的隐状态，作为全连接层的输入，\n",
    "        # 其形状为（批量大小，4*隐藏单元数）\n",
    "        encoding = torch.cat((outputs[0], outputs[-1]), dim=1)\n",
    "        outs = self.decoder(encoding)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aae832b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:47.042284Z",
     "iopub.status.busy": "2022-12-07T17:01:47.041644Z",
     "iopub.status.idle": "2022-12-07T17:01:47.116636Z",
     "shell.execute_reply": "2022-12-07T17:01:47.115760Z"
    },
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, h = config['embed_size'], config['num_hiddens'], config['num_layers'], config['h']\n",
    "devices = try_all_gpus()\n",
    "net = BiRNN(len(vocab), embed_size, num_hiddens, num_layers, h=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a1f1d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:47.120514Z",
     "iopub.status.busy": "2022-12-07T17:01:47.119938Z",
     "iopub.status.idle": "2022-12-07T17:01:47.128015Z",
     "shell.execute_reply": "2022-12-07T17:01:47.127252Z"
    },
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiRNN(\n",
       "  (embedding): Embedding(1447, 100)\n",
       "  (encoder): LSTM(100, 120, num_layers=2, bidirectional=True)\n",
       "  (decoder): Linear(in_features=480, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    if type(m) == nn.LSTM:\n",
    "        for param in m._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(m._parameters[param])\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88f89d7b",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "为词表中的单词加载预训练的100维（需要与`embed_size`一致）的GloVe嵌入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83a6913e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:47.131501Z",
     "iopub.status.busy": "2022-12-07T17:01:47.130877Z",
     "iopub.status.idle": "2022-12-07T17:02:05.289007Z",
     "shell.execute_reply": "2022-12-07T17:02:05.288074Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class TokenEmbedding:\n",
    "    \"\"\"Token Embedding.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Defined in :numref:`sec_synonyms`\"\"\"\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding()\n",
    "        self.unknown_idx = 0\n",
    "        self.token_to_idx = {token: idx for idx, token in\n",
    "                             enumerate(self.idx_to_token)}\n",
    "\n",
    "    def _load_embedding(self):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        word_vec_dir = config['cwd'] + config['word_vectors']\n",
    "        # GloVe website: https://nlp.stanford.edu/projects/glove/\n",
    "        # fastText website: https://fasttext.cc/\n",
    "        with open(word_vec_dir, 'r') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                # Skip header information, such as the top row in fastText\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
    "        return idx_to_token, torch.tensor(idx_to_vec)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
    "                   for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "glove_embedding = TokenEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e55f33f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:02:05.292991Z",
     "iopub.status.busy": "2022-12-07T17:02:05.292408Z",
     "iopub.status.idle": "2022-12-07T17:02:05.334455Z",
     "shell.execute_reply": "2022-12-07T17:02:05.333411Z"
    },
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1447, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = glove_embedding[vocab.idx_to_token]\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a24f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:02:05.338386Z",
     "iopub.status.busy": "2022-12-07T17:02:05.337573Z",
     "iopub.status.idle": "2022-12-07T17:02:05.343453Z",
     "shell.execute_reply": "2022-12-07T17:02:05.342197Z"
    },
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "net.embedding.weight.data.copy_(embeds)\n",
    "net.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaaa6399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:02:05.347505Z",
     "iopub.status.busy": "2022-12-07T17:02:05.346631Z",
     "iopub.status.idle": "2022-12-07T17:05:53.584506Z",
     "shell.execute_reply": "2022-12-07T17:05:53.583367Z"
    },
    "origin_pos": 23,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 56\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmetric[\u001b[39m2\u001b[39m]\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39mnum_epochs\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39mtimer\u001b[39m.\u001b[39msum()\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m examples/sec on \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     53\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(devices)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m config[\u001b[39m'\u001b[39m\u001b[39mis_train\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m---> 56\u001b[0m     train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n\u001b[0;32m     57\u001b[0m         devices)\n",
      "Cell \u001b[1;32mIn[14], line 40\u001b[0m, in \u001b[0;36mtrain_ch13\u001b[1;34m(net, train_iter, test_iter, loss, trainer, num_epochs, devices)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m i, (features, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_iter):\n\u001b[0;32m     39\u001b[0m     timer\u001b[39m.\u001b[39mstart()\n\u001b[1;32m---> 40\u001b[0m     l, acc \u001b[39m=\u001b[39m train_batch_ch13(\n\u001b[0;32m     41\u001b[0m         net, features, labels, loss, trainer, devices)\n\u001b[0;32m     42\u001b[0m     metric\u001b[39m.\u001b[39madd(l, acc, labels\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], labels\u001b[39m.\u001b[39mnumel())\n\u001b[0;32m     43\u001b[0m     timer\u001b[39m.\u001b[39mstop()\n",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m, in \u001b[0;36mtrain_batch_ch13\u001b[1;34m(net, X, y, loss, trainer, devices)\u001b[0m\n\u001b[0;32m     17\u001b[0m pred \u001b[39m=\u001b[39m net(X)\n\u001b[0;32m     18\u001b[0m l \u001b[39m=\u001b[39m loss(pred, y)\n\u001b[1;32m---> 19\u001b[0m l\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     20\u001b[0m trainer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m train_loss_sum \u001b[39m=\u001b[39m l\u001b[39m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\OrangeX4\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\OrangeX4\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr, num_epochs = config['lr'], config['num_epochs']\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "def train_batch(net, X, y, loss, trainer, devices):\n",
    "    \"\"\"Train for a minibatch with mutiple GPUs (defined in Chapter 13).\n",
    "\n",
    "    Defined in :numref:`sec_image_augmentation`\"\"\"\n",
    "    if isinstance(X, list):\n",
    "        # Required for BERT fine-tuning (to be covered later)\n",
    "        X = [x.to(devices[0]) for x in X]\n",
    "    else:\n",
    "        X = X.to(devices[0])\n",
    "    y = y.to(devices[0])\n",
    "    net.train()\n",
    "    trainer.zero_grad()\n",
    "    pred = net(X)\n",
    "    l = loss(pred, y)\n",
    "    l.sum().backward()\n",
    "    trainer.step()\n",
    "    train_loss_sum = l.sum()\n",
    "    train_acc_sum = accuracy(pred, y)\n",
    "    return train_loss_sum, train_acc_sum\n",
    "\n",
    "def train(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
    "               devices=try_all_gpus()):\n",
    "    \"\"\"Train a model with mutiple GPUs (defined in Chapter 13).\n",
    "\n",
    "    Defined in :numref:`sec_image_augmentation`\"\"\"\n",
    "    timer, num_batches = Timer(), len(train_iter)\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    for epoch in range(num_epochs):\n",
    "        # Sum of training loss, sum of training accuracy, no. of examples,\n",
    "        # no. of predictions\n",
    "        metric = Accumulator(4)\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            l, acc = train_batch(\n",
    "                net, features, labels, loss, trainer, devices)\n",
    "            metric.add(l, acc, labels.shape[0], labels.numel())\n",
    "            timer.stop()\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (metric[0] / metric[2], metric[1] / metric[3],\n",
    "                              None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n",
    "          f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n",
    "          f'{str(devices)}')\n",
    "\n",
    "if config['is_train']:\n",
    "    train(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
    "        devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0031de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:05:53.588312Z",
     "iopub.status.busy": "2022-12-07T17:05:53.587686Z",
     "iopub.status.idle": "2022-12-07T17:05:53.593656Z",
     "shell.execute_reply": "2022-12-07T17:05:53.592571Z"
    },
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def predict(net, vocab, sequence):\n",
    "    \"\"\"预测文本序列的情感\"\"\"\n",
    "    inputs = vocab[sequence.split()]\n",
    "    inputs = truncate_pad(inputs, num_steps, vocab['<pad>']) + [1] * num_steps\n",
    "    sequence = torch.tensor(inputs, device=try_gpu())\n",
    "    label = torch.argmax(net(sequence.reshape(1, -1)), dim=1)\n",
    "    return label\n",
    "\n",
    "def predict_sentiment(net, vocab, sequence):\n",
    "    label = predict(net, vocab, sequence)\n",
    "    return 'positive' if label == 2 else ('neutral' if label == 1 else 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea204e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:05:53.597553Z",
     "iopub.status.busy": "2022-12-07T17:05:53.596519Z",
     "iopub.status.idle": "2022-12-07T17:05:53.604987Z",
     "shell.execute_reply": "2022-12-07T17:05:53.603912Z"
    },
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ec9ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:05:53.608087Z",
     "iopub.status.busy": "2022-12-07T17:05:53.607650Z",
     "iopub.status.idle": "2022-12-07T17:05:53.615352Z",
     "shell.execute_reply": "2022-12-07T17:05:53.614282Z"
    },
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e374715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "\n",
    "if config['is_save']:\n",
    "    torch.save(net.state_dict(), config['cwd'] + config['model_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca5a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成最终的结果文件 `result.txt`.\n",
    "\n",
    "if config['is_save_result']:\n",
    "    result = []\n",
    "    with open(config['cwd'] + config['test_data']) as f:\n",
    "        test_data = json.load(f)\n",
    "        test_tokens = [data['tokens'] for data in test_data]\n",
    "        test_dist = [data['dist'][1:] for data in test_data]\n",
    "        test_features = torch.tensor([truncate_pad(\n",
    "            vocab[test_tokens[i]], num_steps, vocab['<pad>']) + truncate_pad(\n",
    "            test_dist[i], num_steps, 100) for i in range(len(test_tokens))])\n",
    "        test_labels = net(test_features.to(try_gpu())).argmax(dim=1).cpu().numpy()\n",
    "        # 0 -> -1, 1 -> 0, 2 -> 1\n",
    "        result = [label - 1 for label in test_labels]\n",
    "    with open(config['cwd'] + config['result_data'], 'w') as f:\n",
    "        for label in result:\n",
    "            f.write(str(label) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
