# 机器学习

## 一、绪论

- 基本术语
    - 数据集中每条记录被称为 **示例** (instance) 或 **样本** (sample)
    - 属性 (特征) 张成的空间称为 **属性空间** 或 **样本空间**
    - 拥有了 **标记** 信息的示例, 则称为 **样例** (example)
    - 所有标记组成的集合又称为 **标记空间** 或者 **输出空间**
    - 从 **训练集** 中学得模型的过程称为 **学习** 或 **训练**, 学得的模型称为 **假设**
    - 假设想要得到的这种潜在规律称为 **真相**
    - 根据训练数据是否有标记信息, 学习任务大致可以划分为 **监督学习** 和 **无监督学习**, 分类和回归是前者的代表, 聚类是后者的代表
    - 学得模型适用于新样本的能力称为 **泛化** 能力
    - 为了能得到有强泛化能力的模型, 我们希望训练集能够很好地反映出样本空间的特性
    - 通常假设样本空间中全体样本服从一个未知分布 $\mathcal{D}$, 我们获得的每个样本都是从该分布独立采样得到的, 即 **独立同分布** (independent and identically distributed)
        - **为什么需要独立同分布假设?**
        - 因为我们关注的是泛化性, 希望用训练数据集训练得到的模型可以合理用于测试集
        - 如若没有独立同分布条件, 未见样本就可能会大大偏离了训练集的范围, 我们训练得到的模型就无能为力了
- 假设空间
    - 从样例中学习显然不是演绎, 而是归纳的过程, 因此亦称 **归纳学习**
    - 我们可以把学习过程看作一个在 **所有假设组成的空间** 上搜索的过程
    - 存在一个与训练集一致的 **假设集合**, 我们称之为 **版本空间**
- 归纳偏好
    - 因为版本空间可能存在多个假设, 所以我们需要确定性地从中取出一个
    - 机器学习算法在学习过程中对某种类型假设的偏好, 称为 **归纳偏好**
    - **归纳偏好看似和特征选择有关, 但是实则不同**
        - 特征选择仍然是基于对训练样本的分析进行的
        - 而归纳偏好并非基于特征选择进而对某种特征更重视, 而是某种已知的领域知识
    - **奥卡姆剃刀**: 若有多个假设与观察一致, 则选择最简单的那个
        - 但是奥卡姆剃刀原则也并不平凡: 我们如何定义哪一个更 "简单" 呢
    - **NFL 定理**: 脱离具体问题, 空谈 "什么学习算法更好" 毫无意义, 因为若考虑所有潜在问题, 则所有学习算法一样好
        - NFL 有一个重要前提: 所有问题出现的机会都相同
        - 但是实际上并不会有这个前提, 我们一般只关注某个具体的任务
        - 寓意: 脱离具体的问题, 空谈什么学习算法更好是毫无意义的


## 二、模型评估与选择

- 经验误差和过拟合
    - **经验误差**: 学习器在训练集上的误差, 也叫 **训练误差**
    - **泛化误差**: 学习器在新样本上的误差
    - **过拟合**: 模型将训练样本本身的一些特点当作了所有潜在样本会有的一般性质, 这样会导致泛化性能的下降, 被称为过拟合
    - **过拟合产生的原因**
        - **学习能力过于强大**, 以至于学到了训练集的特殊性质
        - **训练数据集过小**, 未包含足够的数据样本, 无法很好的反映潜在分布
        - 训练数据中 **包含了噪声**
        - 在单个样本训练集中训练时间过长
    - **为什么过拟合只能缓解**
        - 可以简单地理解, 机器学习所面临的通常是 NP-hard 的问题, 而有效的学习算法必然是在多项式时间内完成的, 若可以彻底避免过拟合, 说明我们就证明了 $P = NP$. 因此只要我们相信 $P \neq NP$, 过拟合就是不可避免的
    - **如何缓解过拟合**
        - **验证集**: 使用验证集选择恰当的超参数, 避免算法学习能力过强
        - **早停**: 在训练轮数过多之前停止, 以避免学到更多的训练集特化的性质
        - **正则化**: 一般来说简单的模型更不容易过拟合, 加入正则化项以获得更简单的模型
        - **修剪**: 根据我们要预测的内容, 借助领域知识, 去除一些不相关的特征
        - **集成学习**: 综合多个弱学习器的结果, 获得泛化性能更好, 更准确的结果
        - **数据增强**: 通过一些领域特定的方式略微更改样本数据, 增加数据集的大小, 进而得到更好的泛化性能
    - **模型选择问题**: 选择哪一种学习算法, 哪一种超参数配置, 进而引出了如何进行模型评估的问题
- **评估方法**
    - **留出法** (hold-out): 直接将数据集 $D$ 划分为两个互斥的集合, 其中一个集合作为训练集 $S$, 另一个作为测试集 $T$.
        - 要尽可能保持数据分布一致性, 例如使用分层采样的方式.
        - 因为样本划分不同可能引入差别, 单次留出法估计结果往往不够稳定可靠, 一般要采用若干次随机划分, 重复进行实验评估后取平均值作为评估结果.
        - **训练样本和测试样本的比例也很重要, 测试集过小时, 评估结果的方差较大; 训练集过小时, 评估结果的偏差较大**
    - **交叉验证法** (cross validation): 先将数据集 $D$ 划分为 $k$ 个大小相似的互斥子集, 每个子集 $D_i$ 都尽可能保持数据分布一致性, 即从 $D$ 中通过分层采样得到. 因此经常也叫 $k$ 折交叉验证.
        - 为了减少因样本划分不同而引入的差别, $k$ 折交叉验证通常要随机使用不同的划分重复 $p$ 次.
        - **留一法** (LOO): 令 $k=m$ 则得到了 $k$ 折交叉验证法的一个特例, 留一法. 留一法中被实际评估的模型与期望评估的用 $D$ 训练出的模型很相似. 留一法不受随机样本划分方式的影响.
    - **自助法 (bootstrapping)**: 有放回地重复采样出 $m$ 个样本, 得到新的数据集 $D'$, $m$ 取极限可得不被采样到的概率为 $1 / e = 0.368$.
        - **可以减少因为样本训练规模不同而导致的估计偏差**
        - 将自助法没被采样到的样本用于测试, 这样的测试结果称为 **包外估计**
        - 自助法在数据集较小, 难以有效划分训练/测试集时很有用
        - 自助法能从初始数据集中产生多个不同的训练集, 对集成学习等方法有很大好处
        - 自助法产生的数据集改变了初始数据集的分布, 会引入估计偏差
        - 在初始数据量足够的情况下, 留出法和交叉验证法更常用
    - 在模型选择完成后, 学习算法和参数配置都已选定, 此时应该用数据集 $D$ 重新训练模型, 充分利用所有样本.
    - 我们常把模型在实际使用中遇到的数据称为测试数据, 为了加以区分, 模型评估与选择中用于评估测试的数据常称为 **验证集**
- 性能度量
    - 回归任务常用均方误差: $\displaystyle E(f; D) = \frac{1}{m}\sum_{i=1}^{m}(f(\bm{x}_i)-y_i)^{2}$
        - $\displaystyle E(f; \mathcal{D}) = \int_{\bm{x}\sim \mathcal{D}} (f(\bm{x})-y)^{2}p(\bm{x})\mathrm{d}\bm{x}$
    - 分类任务常用错误率和精度: $\displaystyle E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}(f(\bm{x}_i \neq y_i))$
    - **查准率和查全率**
        - $\displaystyle P = \frac{TP}{TP + FP}$
        - $\displaystyle R = \frac{TP}{TP + FN}$
        - 查准率和查全率是一对相互矛盾的度量
        - 如果我们能够根据学习器的预测结果对样例进行排序, 以此顺序逐个把样本作为正例进行预测, 则每次可以计算出当前的查全率和查准率, 进行作图, 然后就得到了 **P-R 曲线**
        - P-R 曲线是非单调, 不平滑, 局部有很多上下波动的曲线
        - 如果一个学习器的 P-R 曲线完全包住了另一个学习器的 P-R 曲线, 则可断言前者的性能优于后者
        - 对于 P-R 曲线有交叉的学习器, 则不太好判断. 一般而言我们可能希望判断 P-R 曲线下的面积大小, 但是这个值不太容易估算, 因此我们设计了另外一些综合考虑查准率和查全率的性能指标
        - **平衡点 BEP**: 它是查准率等于查全率时的取值, 但是还是过于简化了
        - **F1 度量**: $\displaystyle F_1 = \frac{2 \times P \times R}{P + R}$
        - 一般形式: $\displaystyle F_{\beta} = \frac{(1 + \beta^{2}) \times P \times R}{(\beta^{2} \times P) + R}$
        - 当我们有多个二分类混淆矩阵时, 我们用不同的方式计算即可得到 "宏" 指标和 "微" 指标
            - **宏 (marco)**: 先计算出各个指标, 再对指标求平均
                - 适合用于类别不平衡的问题
            - **微 (micro)**: 先将混淆矩阵对应元素进行平均, 再计算得到指标
    - ROC 与 AUC
        - 与 P-R 曲线类似
        - 真阳率 $\displaystyle TPR = \frac{TP}{TP + FN}$
        - 伪阳率 $\displaystyle FPR = \frac{FP}{TN + FP}$
        - ROC 曲线是单调的, 这点与 P-R 曲线不同
        - 随机猜测答案的学习器的 ROC 曲线是对角线
        - 我们比较 ROC 曲线下的面积, 即 AUC (Area Under ROC Curve)
    - 代价敏感错误率与代价曲线
        - 我们可以使用代价矩阵
        - 在非均等代价下, ROC 曲线不能直接反映出学习器的期望总体代价
        - 我们可以使用代价曲线 (cost curve)
            - 横轴为正例概率代价
            - 纵轴为归一化代价
            - 我们将 $(0, FPR)$ 和 $(1, FNR)$ 连接, 就能将 ROC 上的每一点转成代价平面上的一条线段
            - 取所有线段的下界, 围成的面积即为期望总体代价
- 比较检验
    - 评估比较的困难
        - 我们希望比较泛化性能, 然而我们得到的确实测试集上的性能
        - 测试集上的性能与测试集本身的选择有很大的关系
        - 很多学习算法本身就包含着一定的随机性
    - 统计假设检验 (hypothesis test) 为我们进行学习器性能比较提供了重要依据. 基于假设检验结果可以推断出, 若在测试集上学习器 A 比 B 好, 那么 A 的泛化性能在统计意义上优于 B 的把握有多大, 也就是概率有多大.
    - **假设检验**
        - 泛化错误率为 $\epsilon$ 的学习器在一个样本上犯错的概率为 $\epsilon$
        - 测试错误率 $\hat{\epsilon}$ 是基于 $\epsilon$ 的一个二项分布
        - **单个学习器**
            - **单次留出法** 可以使用 **二项检验** 来对 $\epsilon \le 0.3$ 这样的假设进行检验
            - **重复留出法** 或 **交叉验证法** 可以采用 **t 检验** 的方式
        - **两个学习器** 与 **单个数据集**
            - **k 折交叉验证** 可用 **成对 t 检验** 来进行比较检验
            - **二分类问题** 可以根据两个学习器结果得到 **列联表**, 然后得到一个 **卡方分布**, 进而使用 **McNemar 检验**
        - **多个学习器** 与 **一组数据集**
            - 基于算法排序的 **Friedman 检验**, 根据算法在每个数据集上的测试结果进行排序并赋予序值 (相同时平分序值), 再求平均得到平均序值
            - 但是 Friedman 检验只能判断出算法是否性能相同, 还需要后续检验进一步区分个算法, 常用的有 **Nemenyi 后续检验**
            - Nemenyi 检验计算出平均序值的临界值域, 若临界值域没有交叉, 说明序靠前的算法显著优于靠后的算法
    - **偏差和方差**
        - **对回归任务的均方误差 (MSE) 进行分解**
        - 对于回归任务, **泛化误差** 可以分解为 (**对训练集 $D$ 求期望**)
            $$
            \begin{aligned}
            E(f;D) &= \mathbb{E}_{D}[(f(\bm{x};D)-y_{D})^{2}]  \\
            &= \mathbb{E}_{D}[(f(\bm{x};D)-\bar{f}(\bm{x}))^{2}] + (\bar{f}(\bm{x})-y)^{2} + \mathbb{E}_{D}[(y_{D}-y)^{2}]  \\
            &= \operatorname{bias}^{2}(\bm{x}) + \operatorname{var}(\bm{x}) + \epsilon^{2}
            \end{aligned}
            $$
        - 也就是 **偏差**, **方差** 和 **噪声** 之和
            - **偏差刻画了学习算法本身的拟合能力**
            - 方差度量了同样大小的训练集的变动所导致的学习性能的变化, 即数据扰动所造成的影响, **是数据的充分性**
            - 噪声表达了当前任务任何学习算法期望泛化误差的下界, **是问题本身的难度**
        - 偏差和方差是有冲突的, 称为偏差-方差窘境.
            - **随着训练程度加深, 偏差不断减小, 但是方差不断增大**
            - 训练不足时, 学习器的拟合能力不强, 训练数据扰动不足以使学习器发生显著变化, 则 **此时偏差主导了泛化错误率**
            - 训练充足时, 训练数据发生的扰动能被学习器学习到, 因此方差逐渐主导了泛化错误率


## 三、线性模型

- **线性回归**
    - 试图学习一个线性模型尽可能准确地预测输出标记
    - 离散属性如果存在序关系, 则可以通过连续化转化为连续值
    - 离散数学如果不存在序关系, 则可以通过 one-hot 的方式转为 k 维变量
    - 基于均方误差最小化求解的方法称为最小二乘法
    - 首先对 $X$ 进行 **齐次化**, 一行一个数据
    - 就可以优化得到 $\hat{\omega} = (X^{T}X)^{-1} X^{T}y$
    - **当 $X^{T}X$ 不满秩时, 可以引入正则化项得到 $X^{T}X + \lambda I$**
        - $X^{T}X + \lambda I$ 总是可逆的, 因为它是半正定矩阵和正定矩阵的和, 因此一定是正定矩阵, 则一定满秩
        - $u^{T}(X^{T}X + \lambda I)u = (Xu)^{T}(Xu) + \lambda Iu^{T}u \ge \lambda Iu^{T}u > 0$
        - 不引入正则化项的话, 可能存在多个 $\hat{\omega}$ 都能使均方误差最小化
        - 向优化问题加入正则化项 $\lambda \omega^{T}\omega$ 即加入了一个归纳偏好, 可以让模型参数偏向于较小, 进而模型更为简单
- **对数线性回归**: $\ln y - \bm{w}^{\mathrm{T}}\bm{x}+b$.
    - 更一般地, 对于单调可微函数 $g(\cdot)$: $y = g^{-1}(\bm{w}^{\mathrm{T}}\bm{x}+b)$
    - 这样的模型为广义线性模型, 其中 $g(\cdot)$ 为联系函数 (link function).
- **对数几率回归**
    - 对数几率回归是 **分类模型**, 本质是
        - $\displaystyle \ln \frac{y}{1-y}=\bm{w}^{\mathrm{T}}\bm{x}+b$ 
        - 即 $\displaystyle y = \frac{1}{1+e^{-(\bm{w}^{\mathrm{T}}\bm{x}+b)}}$.
        - 我们将其改写为 $\displaystyle \ln \frac{p(y=1|\bm{x})}{p(y=0|\bm{x})} = \bm{w}^{\mathrm{T}}\bm{x}+b$
    - 其中 $\displaystyle \ln \frac{y}{1 - y}$ 被称为对数几率, 即几率 (**正类可能性与负类可能性的比值**) 的对数
    - 使用极大似然估计得到对数似然函数 $\displaystyle \ell(\beta) = \sum_{i=1}^{m} (-y_i \beta^{T}\hat{x}_i + \ln(1 + e^{\beta^{T}\hat{x}_i}))$
        - 令 $\beta = (w, b)^{T}$, 也即齐次化, $X$ 同理
        - 使用梯度下降法来优化: $\displaystyle w = w - lr \cdot \frac{\partial \ell(\beta)}{\partial \beta}$
        - 其中 $\displaystyle \frac{\partial \ell(\beta)}{\partial \beta} = \sum_{i=1}^{m}\hat{x}_i(p_1(\hat{x}_i; \beta) - y_i)$
        - 可以用矩阵形式改写为 $\displaystyle \frac{\partial \ell(\beta)}{\partial \beta} = X^{T}(\hat{y} - y)$
        - 使用牛顿法的更新公式 $\displaystyle \beta^{t+1} = \beta^{t} - (\frac{\partial^{2} \ell(\beta)}{\partial \beta \partial \beta^{T}})^{-1} \frac{\partial \ell(\beta)}{\partial \beta}$
    - 对于参数 $\beta$ 来说, 对率回归的目标函数 $\displaystyle y = \frac{1}{1 + e^{-(\beta^{T}x)}}$ 是非凸的, 但是其对数似然函数 $\displaystyle \ell(\beta) = \sum_{i=1}^{m}(-y_i \beta^{T}\hat{x}_i + \ln (1 + e^{\beta^{T}\hat{x}_i}))$ 是凸的
- **线性判别分析 LDA**
    - 和 PCA 最大的不同在于 **LDA 是有监督学习**
    - 使同类样本投影点的协方差尽可能小 (同类样本尽可能接近), 异类样本投影点的类中心距离尽可能大 (异类样本尽可能远离)
    - **二分类**
        - 类内散度矩阵 $S_{w} = \Sigma_0 + \Sigma_1$ 以及 $w^{\mathrm{T}}S_{w}w$ 尽可能小
        - 类间散度矩阵 $S_{b} = (\mu_0 - \mu_1)^{\mathrm{T}}(\mu_0 - \mu_1)$ 以及 $w^{\mathrm{T}}S_{b}w$ 尽可能大
        - 则有最大化 $S_{b}$ 和 $S_w$ 的广义瑞利商 $\displaystyle J = \frac{w^{\mathrm{T}}S_b w}{w^{\mathrm{T}}S_w w}$
        - 令 $w^{T}S_w w = 1$ 得到优化问题, 然后使用拉格朗日乘子法可得
        - $w = S_w^{-1} (\mu_0 - \mu_1)$
    - **多分类**
        - 全局散度矩阵: $\displaystyle S_t = S_{b} + S_w = \sum_{i=1}^{m}(x_i - \mu)(x_i - \mu)^{T}$
        - 类内散度矩阵: $\displaystyle S_w = \sum_{i=1}^{N}\sum_{x\in X_i} (x - \mu_i)(x - \mu_i)^{T}$
        - 类间散度矩阵: $\displaystyle S_{b} = S_t - S_w = \sum_{i=1}^{N}m_i(\mu_i - \mu)(\mu_i - \mu)^{T}$
        - 仅当 $N = 2$ 且 **两个类别样本个数相等** 时, 才有二分类和多分类的 $S_{b}$ 优化结果一致
        - 我们解广义特征值问题 $S_{b} W = \lambda S_{w} W$
        - $W$ 的闭式解为由 $S_w^{-1} S_{b}$ 的 $N - 1$ 个最大广义特征值对应特征向量组成的矩阵 (因为 $S_{b}$ 的秩最高为 $N - 1$)
        - 将 $W$ 视作一个投影矩阵, 则多分类 LDA 将样本投影到 $N - 1$ 维空间, 因此 LDA 也被视为一种经典的有监督降维方法
    - LDA 可从贝叶斯决策理论的角度来诠释, 在两类数据同先验, 满足高斯分布且协方差相等时, LDA 可以达到最优分类
- **多分类学习**
    - 我们尝试将多分类问题归约到二分类问题, 然后使用二分类学习器来解决
    - OvO 每次将 $N$ 个类别两两配对, 产生 $N(N-1)/2$ 个二分类任务, 最后结果通过投票产生.
    - OvR 每次将一个类作为正例, 其余作为反例, 最后选择置信度最大的类别作为分类结果.
    - MvM 是将若干个类作为正类, 若干个类作为反类, 显然 OvO 和 RvR 是 MvM 的特例
    - **输出纠错码**, 一种最常用的 MvM 技术
        - 编码: 对 N 个类进行 M 次划分, 得到 M 个分类器
        - 解码: M 个分类器分别对测试样本预测, 预测结果组成一个编码, 将编码与各自的编码进行比较, 返回距离最小的类别最为最终预测结果
        - 海明距离: 两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数
        - 常用的有二元码 (正类和反类), 以及三元码 (正类, 反类以及停用类)
        - 有一定的纠错能力
        - 理论上说, 我们需要让任意两个类别之间的编码距离更远, 这是 NP 难问题
- **类别不平衡**
    - 对 OvR 和 MvM 来说, 由于对每个类进行了相同的处理, 其得到的二分类任务中类别不平衡的影响会相互抵消, 因此不需要专门处理
    - 我们在使用几率 $\displaystyle \frac{y}{1 - y} > 1$ 时, 应该考虑到类别不平衡问题, 因此可以改为 $\displaystyle \frac{y}{1 - y} > \frac{m^{+}}{m^{-}}$, 或者 $\displaystyle \frac{y'}{1 - y'} = \frac{y}{1 - y} \times \frac{m^{-}}{m^{+}}$, 这种思想被称为 **再缩放** 或者 **再平衡**
    - **欠采样** 根据训练集去除一些反例, 例如集成学习的 EasyEnsemble
    - **过采样** 根据训练集增加一些正例, 例如 SMOTE, 通过插值产生额外的正例
        - 过采样一般不能直接对样本进行简单重复采样, 不然可能会过拟合
    - 使用原始训练集训练, 但是加入 $\displaystyle \frac{y'}{1 - y'} = \frac{y}{1 - y} \times \frac{m^{-}}{m^{+}}$, 称为 **阈值移动**
    - 再缩放也是 **代价敏感学习**


## 四、决策树

- **决策树的生成**
    - 决策树的生成是一个递归的过程, 只有三种情形会导致递归返回
        - 当前节点包含的样本全部属于同一个类别 $C$, 则标记为 $C$ 类叶节点
        - 当前属性集为空, 或者样本在所有属性上取值相同, 无法区分, 则标记为样本中最多的类别叶节点 (这是利用当前节点的后验分布)
        - 当前节点包含样本集合为空, 则标记为父节点中样本中最多的类别叶节点 (这是将父节点样本分布当成当前节点先验分布)
    - 决策树的重点是 **如何划分选择最优划分属性**
- **划分选择**
    - 信息熵: $\displaystyle \operatorname{Ent}(D) = -\sum_{k=1}^{|\mathcal{Y}|}p_k \log_2 p_k$
        - 信息熵越小, 纯度越高.
    - 信息增益: $\displaystyle \operatorname{Gain}(D, a) = \operatorname{Ent}(D) - \sum_{v=1}^{V}\frac{|D^{v}|}{|D|}\operatorname{Ent}(D^{v})$
        - 信息增益越大, 纯度提升越大.
    - 增益率: $\displaystyle \operatorname{Gain\_ratio}(D, a) = \frac{\operatorname{Gain}(D, a)}{\operatorname{IV}(a)}$
        - 其中 $\displaystyle \operatorname{IV}(a) = -\sum_{v=1}^{V}\frac{|D^{v}|}{|D|}\log_2 \frac{|D^{v}|}{|D|}$ 称为属性 $a$ 的固有值.
    - 信息增益对取值数目较多的属性有所偏好, 增益率对取值数目较少的属性有所偏好
    - C4.5 先从候选划分属性中找出信息增益高于平均水平的属性, 再从中选择增益率高的.
    - CART 决策树使用基尼指数.
        - 基尼值: $\displaystyle \operatorname{Gini}(D) = \sum_{k=1}^{|\mathcal{Y}|}\sum_{k'\neq k}p_k p_{k'} = 1-\sum_{k=1}^{|\mathcal{Y}|}p_k^{2}$
        - 基尼指数: $\displaystyle \operatorname{Gini\_index}(D,a) = \sum_{v=1}^{V}\frac{|D^{v}|}{|D|}\operatorname{Gini}(D^{v})$
        - 直观来说, 基尼值反映了从数据集中随机抽取两个样本, 其类别标记不一致的概率
        - 我们选择基尼指数小的属性作为最优划分属性.
- **剪枝处理**
    - 剪枝是决策树算法应付过拟合的主要手段
    - **预剪枝** 是在决策树生成过程中, 对每个节点在划分前先进行估计, 若不能带来泛化性能的提升, 则停止划分, 并将当前节点标记为叶节点
        - 预剪枝是贪心的, 可以降低过拟合的风险, 还可以减少训练时间开销
        - **但是也会带来欠拟合的风险**
    - **后剪枝** 则是先生成一棵完整的决策树, 再自底向上地对非叶节点考察, 若替换成叶节点能够带来泛化性能的提升, 则替换为叶节点
        - **欠拟合风险很小, 而且泛化性能往往优于预剪枝**
        - 但是训练开销比未剪枝和预剪枝决策树都大得多
- **连续值处理**
    - 采用 **二分法**
    - 包含 $n-1$ 个元素的候选划分点集合 $\displaystyle T_a = \{ \frac{a^{i}+a^{i+1}}{2} | 1 \le i \le n-1 \}$
    - $\displaystyle \operatorname{Gain}(D, a) = \max_{t \in T_a} \operatorname{Gain}(D, a, t)$, 即选择使得 $\operatorname{Gain}(D, a, t)$ 最大化的二分划分点
- **缺失值处理**
    - **核心思想是维护样本权重**, 将缺失值对应样本 "均匀" 地划分到各个取值分支上
- **多变量决策树**
    - 单变量决策树可以看作是通过一系列与坐标轴平行的段组成分类边界
    - 但是如果真实分类边界很复杂时, 需要多段划分才能得到较好的近似
    - **多变量决策树** 就是试图将多个变量组合, 以找到 "斜划分"


## 五、神经网络

- 感知机由两层神经元组成 (但是单层网络), 输出层是 M-P 神经元, 亦称阈值逻辑单元
    - 两个输入神经元, 则有参数 $w_1, w_2, \theta$
    - 如果问题是线性可分的, 则感知机的学习一定会收敛
    - 但是如果不是线性可分的, 例如异或, 就无法解决 (会振荡)
- 只由全连接层组成的网络称为多层前馈神经网络
- n + 1 层神经元 = n 层网络 = n - 1 隐层
- BP 算法依靠的是梯度下降
- **标准 BP 算法**
    - 每次针对单个训练样例更新权值与阈值
    - 参数更新频繁, 不同样例可能抵消, 需要多次迭代
- **累积 BP 算法**
    - 其优化目标是最小化整个训练集上的累计误差
    - 读取整个训练集一遍才对参数进行更新, 参数更新频率较低
- 累计误差下降到一定程度之后, 进一步下降会非常缓慢, 这时使用标准 BP 算法往往会获得较好的解
- 读取训练集一遍称为进行了一轮 (one round / one epoch) 学习.
- 降低过拟合: **早停** 和 **正则化**
- 跳出局部最小
    - 用多组不同的参数初始化进行搜索, 从不同的局部最小挑选一个最小的
    - **模拟退火技术**, 在每一步都以一定的概率接受更差的结果
    - **随机梯度下降**, 在计算梯度时加入了随机因素, 即使在局部极小点梯度仍可能不为零
- 其他神经网络
    - RBF 网络
    - ART 网络
    - SOM 网络
    - 级联相关网络
    - Elman 网络
    - Boltzmann 机
    - 深度学习
        - 节省训练开销
            - 预训练 + 微调
            - 权共享, 例如卷积神经网络
        - 避免梯度消失
            - ReLU
        - Dropout
        - 交叉熵


## 六、支持向量机

- 支持向量机应用于 **线性可分** 问题
- 样本空间任意点 $\bm{x}$ 到超平面 $\bm{w}^{\mathrm{T}}\bm{x}+b=0$ 的距离为 $\displaystyle r=\frac{|\bm{w}^{\mathrm{T}}\bm{x}+b|}{\left\| \bm{w} \right\|}$
- 距离超平面最近的几个样本使得 $y_i(\bm{w}^{\mathrm{T}}\bm{x}_b)\ge 1$ 等号成立, 称为 **支持向量**
- 两个异类支持向量到超平面的距离 $\displaystyle \gamma = \frac{2}{\left\| \bm{w} \right\|}$ 被称为 **间距** (margin)
- 最大化间距等价于
    $$
    \begin{aligned}
    \min_{\bm{w},b} &\quad \frac{1}{2}\left\| \bm{w} \right\|^{2}  \\
    \text{s.t.} &\quad y_i(\bm{w}^{\mathrm{T}}\bm{x}+b) \geq 1, i=1,2,\cdots,m  \\
    \end{aligned}
    $$
- 可以构造出拉格朗日函数 $\displaystyle L(\bm{w}, b, \bm{\alpha}) = \frac{1}{2}\left\| \bm{w} \right\|^{2} + \sum_{i=1}^{m}\alpha_i(1-y_i(\bm{w}^{\mathrm{T}}\bm{x}_i + b))$, 其中 $\alpha_i \ge 0$
- 求偏导等于零之后最后可以将问题化为对偶形式
    $$
    \begin{aligned}
    \max_{\bm{\alpha}} &\quad \sum_{i=1}^{m}\alpha_i - \frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i \alpha_j y_i y_j \bm{x}_i^{\mathrm{T}}\bm{x}_j \\
    \text{s.t.} &\quad \sum_{i=1}^{m}\alpha_i y_i = 0  \\
                &\quad \alpha_i \ge 0, i=1,2,\cdots ,m  \\
    \end{aligned}
    $$
- 一般问题为什么要用拉格朗日对偶: 对偶问题一定是一个凸问题, 并且对偶问题的解一定是原问题解的一个下界, 如果满足了 Slater 条件就还有强对偶性
- 为什么 SVM 问题要转换为对偶形式呢?
    - 在原问题下, 求解算法的复杂度与样本维度 (等于权值 $w$ 的维度) 有关; 而在对偶问题下, 求解算法的复杂度与样本数量 (等于拉格朗日算子 $a$ 的数量) 有关
    - 原问题转换为对偶问题后, 可以使用 SMO 算法, 是二次规划问题, 二次规划问题相对是有成熟的方法来解决. 
    - 原问题转换为对偶问题后, 支持向量会更加清晰, 并且出现内积, 进而可以引入非线性问题的核函数 
- 满足 **KKT 条件** 中的 **互斥松弛性质** $\alpha_i(y_i f(\bm{x}_i)-1) = 0$
- 拉格朗日乘子法
    - **仅有等式约束** 的优化问题可以转化为对拉格朗日函数 $L(x, \lambda)$ 的 **无约束优化问题**
        - 约束曲面上的任意点 $x$, 约束函数 $g(x)$ 在 $x$ 的梯度 $\Delta g(x)$ 正交于约束曲面
        - 最优点 $x^{*}$, 目标函数 $f(x)$ 在 $x^{*}$ 的梯度 $\Delta f(x)$ 正交于约束曲面
    - **有不等式约束** 的优化问题可以转化为拉格朗日函数在 **KKT 条件** 下的 **有约束优化问题**
        - 可以分类成 $g(x) < 0$ 和 $g(x) = 0$ 两种情况来讨论
        - 也可以得知: 只有不等式约束才会也引出不等式约束
        - 这里和对偶问题, 强对偶性无关, 肯定能得到最优结果
    - **拉格朗日对偶函数**: $\displaystyle \Gamma(\lambda, \mu) = \inf_{x \in \mathbb{D}} L(x, \lambda, \mu) \le L(\tilde{x}, \lambda, \mu) \le f(\tilde{x})$
        - 通过拉格朗日对偶函数可以得到对偶问题
- 对偶性
    - 对偶问题总是凸优化问题, 我们可以得到一个原问题最优值的下界, 称为弱对偶性
    - **Slater 约束准则**: 原问题是 **凸问题**, 且存在定义域相对内部 (仿射包的内部) 的一个严格可行点 $x$, 满足 $f_i(x) < 0$
        - 当不等式约束函数有一些是仿射函数时, 那么严格约束的条件可以放松
        - 如果全部是仿射函数, 那么 Slater 条件就只需要是凸问题就满足
        - **在 SVM 中, Slater 约束准则相当于线性可分**
            - SVM 是典型的凸二次优化问题 (QP): $\left\| \omega \right\|^{2} = \omega^{T} I \omega$, 其中 $I$ 为 **半正定矩阵**, 甚至还是正定矩阵, 即一定存在全局最小值
            - 相当于还要存在 $w, b$ 使得 $y_i(w^{T}x_i + b) > 1$
            - 由于线性可分, $w^{*}, b^{*}$ 存在, 只需要令 $w = 2w^{*}, b = 2b^{*}$ 即可有 Slater 条件成立
    - 某些非凸问题也满足强对偶性, 即强对偶性这个条件本身与原问题的凸性无关, 只不过我们发现凸优化问题的强对偶性条件更加特殊
    - **KKT 条件**: 对于目标函数和约束函数可微的任意优化问题, **如果强对偶条件成立**, 那么任何一个原问题最优解和对偶问题最优解 **必须满足 KKT 条件**, 即必要条件, **对于凸问题, KKT 条件是充要条件**, 分为四个部分
        - **原问题可行解**: $f_i(x^{*}) \le 0, h_i(x^{*}) = 0$
        - **对偶问题可行解**: $\lambda^{*} \ge 0$
        - **互斥松弛性**: $\lambda_i^{*} f_i(x^{*}) = 0$
        - **稳定性**: 梯度等于 0
    - 如果原问题是凸问题, 强对偶性一般是成立的 (但不总是有, 仅仅是因为 Slater 条件很容易满足)
    - 由于强对偶性成立, 对偶间隙为 0, 因此对偶问题和原始问题有着相同的最优解
- **重要性质**: 训练完成后, 大部分样本都不需要保留, 最终模型仅与支持向量有关
- 我们可以使用 SMO 算法来高效优化出 $\alpha$.
    - 选取一对需要更新的变量 $\alpha_i$ 和 $\alpha_j$, 选择违背 KKT 条件程度最大的变量和使目标函数减幅较大的变量 (使所选取的两个变量对应样本之间间隔最大);
    - 固定 $\alpha_i$ 和 $\alpha_j$ 以外的参数, 求解该优化问题即可.
    - 重复这两个步骤直至收敛即可.
- 最终模型: $f(\bm{x}) = \bm{w}^{\mathrm{T}}\bm{x}+b=\sum_{i=1}^{m}\alpha_i y_i \bm{x}_i^{\mathrm{T}}\bm{x}+b$
- 核函数
    - 将样本从原始空间映射到一个更高维的特征空间
    - **核函数**: 对任意样本集合得到的核矩阵 $K$ 总是半正定的
        - $\kappa(x, y) = \phi(x)^{T}\phi(y)$
        - 任何一个核函数都隐式定义了一个再生核希尔伯特空间
        - 常见的核函数有线性核, 多项式核, 高斯核 (RBF 核), 拉普拉斯核以及 Sigmoid 核
        - 核函数之和 $\kappa_1 + \kappa_2$, 核函数直积 $\kappa_1 \kappa_2$, 任意 $g(x)\kappa(x, y)g(y)$ 也为核函数
        - **Schur 乘积定理**: 半正定矩阵 $A$ 和 $B$ 的逐元素乘 $A \circ B$ 也是半正定矩阵
    - **核技巧**: 我们不需要计算高维甚至无穷维特征空间中的内积, 而是直接计算核函数值
    - **核方法**: $f(\bm{x})=\sum_{i=1}^{m}\alpha_i y_i \kappa(\bm{x}_i, \bm{x})+b$
    - **表示定理**: 优化问题 $F(h) = \Omega(\left\| h \right\|_{\mathbb{H}}) + \ell(h(x_1), \ldots, h(x_m))$ 的解总能写为 $\displaystyle h^{*}(x) = \sum_{i=1}^{m}\alpha_i \kappa(x, x_i)$
- **软间隔与正则化**
    - 采取 hinge 损失 ($\max(0, 1-z)$) 并引入松弛变量 $\xi_{i}$ 可得 (还可以给样本加入代价系数 $k_i$)
    $$
    \begin{aligned}
    \min_{\bm{w},b} &\quad \frac{1}{2}\left\| \bm{w} \right\|^{2} + C \sum_{i=1}^{m}k_i\xi_{i}  \\
    \text{s.t.} &\quad y_i(\bm{w}^{\mathrm{T}}\bm{x}+b) \geq 1 - \xi_{i}  \\
    &\quad \xi_{i} \ge 0, i=1,2,\cdots,m  \\
    \end{aligned}
    $$
    - 对偶问题
    $$
    \begin{aligned}
    \max_{\bm{\alpha}} &\quad \sum_{i=1}^{n}\alpha_i - \frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{n}\alpha_i\alpha_j y_i y_j\bm{x}_i^{\mathrm{T}}\bm{x}_j\\
    \text{s.t.}
    &\quad \sum_{i=1}^{n}\alpha_i y_i = 0, & 1 \le i \le n  \\
    &\quad 0 \le \alpha_i \le k_i C, & 1 \le i \le n  \\
    \end{aligned}
    $$
    - 如果不用 hinge 损失而用对率损失, 则几乎变成了对率回归模型
    - hinge 损失带有一块平坦的零区域, 这是稀疏性的关键
    - 如果统一写成 $\displaystyle \min_{f} \Omega(f) + C \sum_{i=1}^{m}\ell(f(x_i), y_i)$
        - **结构风险 $\Omega(f)$**: "间隔" 大小, 用于描述 $f$ 的某些性质, 也是正则化项, 从贝叶斯估计角度来看, 正则化项提供了模型的先验概率
        - **经验风险 $\sum_{i=1}^{m}\ell(f(x_i), y_i)$**: 用于描述模型与训练数据的契合程度
- 支持向量回归
    - SVR 假设我们能容忍 $f(x)$ 与 $y$ 之间最多有 $\epsilon$ 的偏差
    - SVR 使用类似 hinge 损失的 $\epsilon$-不敏感损失函数
    - SVR 的支持向量即为落在 $\epsilon$-间隔带之外的向量
    - SVR: $f(\bm{x}) = \sum_{i=1}^{m}(\hat{\alpha}_{i}-\alpha_{i})\bm{x}_i^{\mathrm{T}}\bm{x}+b$
- 重点在于支持向量带来的稀疏性.


## 七、贝叶斯分类器

- **贝叶斯决策理论**
    - **条件风险**: 将样本 $x$ 分类为 $c_i$ 所产生的期望损失
        - $\displaystyle R(c_i|\bm{x})=\sum_{j=1}^{N}\lambda_{ij}P(c_j|\bm{x})$
    - **总体风险**: 为了优化 $h$ 要最小化的风险
        - $\displaystyle R(h)=\mathbb{E}_{\bm{x}}[R(h(\bm{x})|\bm{x})]$
    - **贝叶斯判定准则**: 为了最小化总体风险, 只需要在每个样本上选择使条件风险最小的类别标记
    - **贝叶斯最优分类器**: $\displaystyle h^{*}(\bm{x})=\argmin_{c\in \mathcal{Y}}R(c|\bm{x})$
    - **贝叶斯风险**: 贝叶斯最优分类器对应的总体风险 $R(h^{*})$
- 生成式模型: $\displaystyle P(c|\bm{x})=\frac{P(c)P(\bm{x}|c)}{P(\bm{x})}$
    - 后验概率 = (先验 * 似然) / 证据因子
    - 根据 **大数定律**, 训练集包含充足的 i.d.d. 样本时, $P(c)$ 可以通过各类样本出现频率进行估计
    - 但是类条件概率 (似然) 由于样本过于稀疏, 很难用频率来估计
- **极大似然估计 MLE**
    - **先假定类条件概率具有某种确定的概率分布形式**, 再基于样本进行估计
    - $\displaystyle \hat{\theta}_{c} = \argmax_{\theta_{c}} LL(\theta_c) = \sum_{x \in D_c} \log P(x|\theta_c)$
- **朴素贝叶斯分类器**:
    - 使用了 **属性条件独立性假设**: 已知类别, 假设所有属性互相独立
    - $\displaystyle P(c|\bm{x}) = \frac{P(c)P(\bm{x}|c)}{P(\bm{x})} = \frac{P(c)}{P(\bm{x})}\prod_{i=1}^{d}P(x_i|c)$
    - 离散属性可以直接使用频率估计概率
    - 连续属性可以先假设为具有高斯分布形式
    - 为了避免其他属性携带的信息被训练集中未出现的属性值抹去, 需要进行 **拉普拉斯修正** 来平滑, 即给每一类都新增一个样本
        - 拉普拉斯修正实质上假设了属性值与类别均匀分布, 属于在学习过程中引入了数据的先验
    - 多种使用方式
        - 预测速度要求较高: 可以将所有概率预先计算出来, 后续只需要查表
        - 任务数据更替频繁: 采取懒惰学习的方式, 实际使用时再进行概率估值
        - 数据不断增加情形: 使用在线学习或流式计算的方式, 不断进行计数修正
- **半朴素贝叶斯分类器**
    - **独依赖估计 ODE**: 假设每个属性在类别外最多依赖于一个其他属性
        - 问题关键转化为如何确定每个属性的父属性
    - **SPODE**: 假设所有属性都依赖于同一个属性, 通过交叉验证等模型选择方法确定 **超父** 属性, 得到
    - **TAN**: 以最大带权生成树算法为基础
    - **AODE**: 基于集成学习机制, 尝试将每个属性作为超父构建 SPODE, 再将那些有足够训练数据支撑的 SPODE 集成起来作为最终结果
- **贝叶斯网**
    - 借助有向无环图 DAG 来刻画属性间的依赖关系
    - 常见三种结构
        - 同父结构: 给定父节点的情况下, 两个子节点独立
        - V 型结构: **边际独立性**, 没有给定子节点的时候, 两个父节点独立
            - $P(x, y) = \sum_{z} P(z|x,y)P(x)P(y) = P(x)P(y)$
            - 对变量做求和或者积分叫做边际化
        - 顺序结构: 给定中间节点的情况下, 前后两个节点独立
    - 为了分析图中变量的条件独立性, 可以使用 "有向分离" (D-分离) 的方式
        - 找出图中所有 V 型结构, 在 V 型结构的两个父节点之间加上一条无向边
        - 将所有有向边均变为无向边
        - 这样得到的无向图称为道德图, 令父节点相连的过程称为道德化
        - 道德图可以很方便地判断条件独立性, 只需要判断是否分成两个连通分支即可
- **学习**
    - 贝叶斯网学习的首要任务就是找到结构最恰当的贝叶斯网
    - **评分搜索**: 先定义一个评分函数, 以此来评估贝叶斯网与训练数据的契合程度
    - 常用的评分函数基于信息论, 将学习问题看作一个数据压缩任务, 学习目标是找到一个能以最短编码长度描述训练数据的模型
    - **最小描述长度 MDL 准则**: 选择综合编码长度 (描述网络核编码数据) 最短的贝叶斯网
- **推断**
    - **推断**: 通过已知变量观测值来推测待查询变量的过程, 已知变量被称为 **证据**
    - **精确推断** 是 NP 难问题
    - **近似推断**: 例如 **吉布斯采样**
        - 目标是计算后验概率 $P(Q=q|E=e)$
        - 先随机产生一个与证据 $E=e$ 一致的样本 $q_0$ 作为初始点
        - 不断地依次对非证据变量 $Q_i$ 根据 $P_{B}(Q_i|Z=z)$ 逐个采样改变其值
        - 变化完成后统计 $n_q \leftarrow n_q + 1$
        - 迭代 $T$ 步后即可通过频率估算出后验概率 $\displaystyle P(Q=q|E=e) \approx \frac{n_q}{T}$
        - 由于马尔科夫链需要长时间才能趋于平稳分布, 因此收敛速度很慢
        - 如果贝叶斯网中存在极端概率 $0$ 或者 $1$, 则不能保证存在平稳分布
- EM 算法:
    - 在之前算法中, 我们一直假设训练样本中的变量均为已被观测变量, 但是很多时候我们需要 **隐变量** 的存在, 才能更好地描述一个概率模型
        - 这类问题的特点是, 如果知道了隐变量的真实值, 就可以很简单地对模型参数进行参数估计, 例如 GMM
        - 其实隐马尔科夫模型 HMM 也使用了 EM 算法, 即是 Baum-Wlch 算法
    - 核心想法
        - E 步根据当前数据 $\mathcal{X}$ 和参数值 $\theta^{(t)}$, 找到一个对隐变量 $\mathcal{Z}$ 更好的估计, 这个估计往往是一个概率分布
        - M 步根据当前属于 $\mathcal{X}$ 和对隐变量 $\mathcal{Z}$ 的估计, 通过最大似然法找到参数 $\theta$ 的更好的估计
    - 其实 EM 算法准确来说是分为三步的:
        - **后验**: 计算隐变量后验 $p(z_j|x_j, \theta^{(t)})$
        - **期望**: 找到期望 $\mathcal{Q}(\theta, \theta^{(t)}) = \mathbb{E}_{\mathcal{Z}|\mathcal{X}, \theta^{(t)}}[\ln p(\mathcal{X}, \mathcal{Z}|\theta)]$
        - **最大化**: 找到一个新的参数估计 $\theta^{(t+1)} = \argmax_{\theta} \mathcal{Q}(\theta, \theta^{(t)})$
    - 根据不同的划分方式, 我们可以得到 EM 算法的两步:
        - 模式识别是 E. 后验; M: 期望 + 最大化
        - 机器学习是 E. 后验 + 期望; M: 最大化
    - 机器学习上的理论
        - 我们本来应该最大化对数似然 $LL(\Theta|X, Z) = \ln P(X, Z|\Theta)$
        - 但是 $Z$ 是隐变量, 上式无法直接求解, 因此可以对 $Z$ 求期望来最大化观测数据的 **对数边际似然**
            - $LL(\Theta|X) = \ln P(X|\Theta) = \ln \sum_{Z}P(X,Z|\Theta)$
    - 模式识别上的理论
        - 参数学习问题试图最大化不完整数据对数似然 (对数边缘似然) 来最优化 $\displaystyle \hat{\theta} = \argmax_{\theta} \ln p(\mathcal{X}|\theta)$
        - 设 $q$ 为 $Z$ 的任意一个有效概率分布, 则我们可以使用 KL 散度来衡量 $q(\mathcal{Z})$ 与后验 $p(\mathcal{Z}|\mathcal{X},\theta)$ 的差异
            - **$\ln p(\mathcal{X}|\theta) = \mathcal{L}(q, \theta) + KL(q || p)$**
            - $\displaystyle \mathcal{L}(q, \theta) = \sum_{z} q(\mathcal{Z}) \ln\frac{p(\mathcal{X}, \mathcal{Z}|\theta)}{q(\mathcal{Z})}$
            - $\displaystyle KL(q||p) = -\sum_{z} q(\mathcal{Z}) \ln\frac{p(\mathcal{X}|\mathcal{Z}, \theta)}{q(\mathcal{Z})}$
        - 因此我们分为两步
            - 第一步是使得下界 $\mathcal{L}(q, \theta)$ 等于 $\ln p(\mathcal{X}|\theta)$
                - 即 E 步, KL 等于零, 计算 $\hat{q}(\mathcal{Z}) = p(\mathcal{Z} | \mathcal{X}, \theta)$
            - 第二步是对 $\theta$ 优化 $\mathcal{L}(\hat{q}, \theta)$
                - 这使得 $\ln p(\mathcal{X}|\theta)$ 也会增大, KL 可能不再为零
                - 我们为了优化 $\mathcal{L}(\hat{q}, \theta)$, 等价于优化 $\mathcal{Q}(\theta, \theta^{(t)}) = \mathbb{E}_{\mathcal{Z}|\mathcal{X}, \theta^{(t)}}[\ln p(\mathcal{X}, \mathcal{Z}|\theta)]$
                    - 要注意这里我们是带入了 $\hat{q}(\mathcal{Z}|\mathcal{X}, \theta^{(t)})$, 其中 $\theta^{(t)}$ 属于常量而非变量 $\theta$, 因此不需要优化
                - **也即我们计算对数联合似然 $\ln p(\mathcal{X}, \mathcal{Z}|\theta)$ 对后验分布 $p(\mathcal{Z}|\mathcal{X}, \theta^{(t)})$ 的期望并优化**
                    - 其和边缘对数似然 $\ln p(\mathcal{X}|\theta) = \mathcal{L}(\hat{q}, \theta) + 0 = \mathcal{Q}(\theta, \theta^{(t)}) + \operatorname{const}$ 只相差了常数项
    - KL 散度
        - 熵, 联合熵, 条件熵, 互信息, 相对熵
            - 条件熵: $H(Y|X) = \sum_{x,y} p(x,y) \log_2 p(y|x)$
            - $H(X,Y) = H(X) + H(Y|X) = H(Y) + H(X|Y)$
            - $H(Y|X) \neq H(X|Y)$
            - 互信息: $I(X;Y) = H(X) - H(X|Y)$
            - $I(X;Y) = KL(p(x,y)||p(x)p(y))$
        - KL 散度亦称相对熵或信息散度, 可用于衡量两个概率分布之间的差异
        - $\displaystyle KL(p||q) = \int_{-\infty}^{+\infty} p(x) \ln \frac{p(x)}{q(x)} \mathrm{d} x$
        - **非负性**: $KL(p||q) \ge 0$, 当且仅当 $p = q$ 时取等号
            - 可由琴生不等式证明
        - **不满足对称性**: $KL(p||q) \neq KL(q||p)$, 因此不是一个度量
        - 可以用 KL 散度证明
            - 信息熵 $I(X;Y) = KL(p(x,y)||p(x)p(y))$ 非负
            - $KL(X||U) = \log_{2} m - KL(X||U)$ 可得 $H(X) \le \log_2 m$, 即离散均匀分布对应熵 $\log_2 m$ 是不确定性的上界
            - KL 散度可以用来证明 **最大熵分布**
            - $\displaystyle KL(p||q) = -h(p) + CE(p, q)$
            - 也即 **$p, q$ 的交叉熵 = $p, q$ 的 KL 散度 + $p$ 的熵**
            - **交叉熵是对称的**
            - 熵可以理解为 $p$ 最小编码方式所需最小字节数, 交叉熵可以理解为使用 $q$ 的最小编码方式对 $p$ 编码所需字节数, 那么 KL 散度就变成了使用 $q$ 的编码对 $p$ 变量进行编码所需的 **额外字节数**, 这样也很容易理解 KL 散度的非负性




## 八、集成学习


- 个体与集成
    - 集成学习通过构建并结合多个学习器来完成学习任务
        - 同质集成中的个体学习器亦称基学习器, 相应算法称为基学习算法
        - 异质集成中的个体学习器由不同的学习算法生成, 个体学习器称为组件学习器
    - 集成学习通过将多个学习器结合, 常可获得比单一学习器优越的结果, 这对弱学习器尤为明显
    - 要获得好的集成, 个体学习器应该 **好而不同**
        - **个体学习器一定要有准确性, 不能太坏**
        - **个体学习器之间应有多样性, 学习器间具有差异**
    - 若各分类器的错误率相互独立, 则由 Hoeffding 不等式可知
        - $\displaystyle P(H(x) \neq f(x)) = \sum_{k=0}^{\lfloor T / 2 \rfloor} \binom{T}{k} (1-\epsilon)^{k}e^{T-k} \le e^{-\frac{1}{2}T(1-2\epsilon)^{2}}$
        - 随着分类器数目 $T$ 增大, 集成错误率将指数级下降
    - 但是事实上互相独立是不可能的, 个体学习器的准确性和多样性本身就存在冲突
    - 根据个体学习器的生成方式, 目前集成学习方法大致可分为两大类
        - 个体学习器间存在强依赖关系, 必须串行生成的序列化方法, 以 Boosting 为代表
        - 个体学习器间不存在强依赖关系, 可以同时生成的并行化方法, 以 Bagging 和随机森林为代表
- **AdaBoost**
    - Boosting 是一族可将弱学习器提升为强学习器的算法
    - **工作机制**: 先从初始训练集训练出一个基学习器, 然后再根据基学习器的表现 **对训练样本分布进行调整, 使得先前基学习器做错的训练样本在后续受到更多的关注**, 然后基于调整后的样本分布来训练下一个基学习器; 如此进行, 直至基学习器数目达到事先指定的值 $T$, 最终将这 $T$ 个基学习器进行加权结合.
    - 用加性模型 $H(\bm{x})=\sum_{t=1}^{T}\alpha_{t}h_t(\bm{x})$ 来最小化指数损失函数 $\displaystyle \ell_{\exp}(H|\mathcal{D})=\mathbb{E}_{\bm{x}\sim \mathcal{D}}[e^{-f(\bm{x})H(\bm{x})}]$
    - 指数损失函数是分类任务原本的 0/1 损失函数的一致替代损失函数
        - 通过对 $H(x)$ 求偏导等于零可以解得该结果
    - AdaBoost 是类似于 "残差逼近" 的思想
        - 初始化样本权值分布 $\mathcal{D}_1(x) = 1 / m$
        - 进行 $T$ 次循环
            - 基于分布 $\mathcal{D}_t$ 从数据集 $D$ 中训练出分类器 $h_t$
            - 估计 $h_t$ 的误差: $\epsilon_t = P_{x \sim \mathcal{D}_t}(h_t(x) \neq f(x))$
            - 如果误差已经超过 0.5 了, 则终止循环
                - 这个基学习器还不如随机预测的结果, 如果加入到最终分类器中会影响分类器的性能, 需要抛弃该学习器
            - 确定分类器的权重: $\displaystyle \alpha_t = \frac{1}{2} \ln (\frac{1-\epsilon_t}{\epsilon_t})$
                - $\alpha_t$ 最小化指数损失函数 $\ell_{\exp}(\alpha_t h_t|\mathcal{D}_t)$
            - 更新样本分布 (权值): $\displaystyle \mathcal{D}_{t+1}(x) = \frac{\mathcal{D}_t(x) \exp(-\alpha_t f(x)h_t(x))}{Z_t}$
                - $f(x)h_t(x) = \begin{cases} 1, & f(x) = h_t(x) \\ -1, & f(x) \neq h_t(x) \end{cases}$
                - 其中 $Z_t$ 是规范化因子
        - 输出 $\displaystyle H(x) = \operatorname{sign}(\sum_{t=1}^{T}\alpha_t h_t(x))$
    - Boosting 算法要求基学习器能对特定数据分布进行学习, 可以通过 **重赋权法** 实施, 如果基学习算法无法接受权重, 则可以通过 **重采样法** 来处理
    - 若使用 **重采样法, 还有助于避免训练过程早停**, 即如果当前不满足, 我们可以重新采样, 直至满足为止
    - 从偏差-方差分解角度来看, Boosting 主要关注降低偏差, 因此 Boosting 可以基于泛化性能相当弱 (拟合能力弱) 的学习器构建出很强的集成
- **Bagging 和随机森林**
    - 为了使基学习器尽可能有较大差异, 我们可以对训练样本进行采样, 产生若干不同子集, 再从每个数据子集中训练出一个基学习器, 为了避免基学习器训练样本过少, 我们还可以考虑相互有交叠的采样子集
    - **Bagging**
        - 采取 **自助采样法**, 初始训练集中约有 63.2% 的样本出现在采样集里
        - 可采样出 $T$ 个包含 $m$ 个训练样本的采样集
        - Bagging 对分类任务通常使用简单投票法, 对回归任务使用简单平均法, 相同时则随机选择其中一个
        - 剩下的 36.8% 的样本可用作泛化性能的包外估计, 还可以用于基学习器验证集, 以减少过拟合措施, 如剪枝和早停
        - 从偏差-方差分解来看, Bagging 主要关注降低方差, 因此它在不剪枝决策树, 神经网络等易受到样本扰动 (拟合能力强) 的学习器上效用更为明显
    - **随机森林**
        - 随机森林 RF 是 Bagging 的一个拓展变体
        - 在以决策树为基学习器构建 Bagging 集成的基础上, 进一步在决策树的训练过程中引入了随机属性选择
        - 传统决策树在选择划分属性时是选择一个最优属性, 而 RF 是先随机选择包含 $k$ 个属性的子集, 然后再从子集中选择一个最优属性用于划分, 一般推荐 $k = \log_2 d$
        - RF 简单, 容易实现, 计算开销小, 性能却十分强大, 被誉为代表集成深度学习技术水平的方法
        - 基学习器的 **多样性** 不仅来源于 **样本扰动**, 还来源于 **属性扰动**
- 结合策略
    - 学习器结合可能在三个方面带来好处
        - **从统计方面来看**, 学习任务假设空间往往很大, 可能有多个假设在训练集上达到同等性能, 此时使用单学习器可能因为误选而泛化性能不佳, 结合多学习器可以减少这一风险
        - **从计算方面来看**, 学习算法往往会陷入局部极小, 多次运行可降低陷入糟糕局部极小点的风险
        - **从表示方面来看**, 某些学习任务的真实假设可能不在当前学习算法所考虑的假设空间中, 使用单学习器肯定无效, 通过结合多个学习器, 由于假设空间有所扩大, 有可能学得更好的近似
    - 常见策略
        - 回归任务
            - 平均法
            - 加权平均法: 个体学习器性能相差较大时宜用加权平均法
        - 分类任务
            - 绝对多数投票法
            - 相对多数投票法
            - 加权投票法
            - 还有硬投票和软投票之分
        - 学习法
            - 个体学习器称为初级学习器, 用于结合的学习器称为次级学习器或元学习器
            - Stacking 是学习法的典型代表
- **多样性**
    - 误差-分歧分解
        - 分歧 $A(h_i|x) = (h_i(x) - H(x))^{2}$
        - $\displaystyle \bar{A}(h|x) = \sum_{i=1}^{T}w_i E(h_i|x) - E(H|x)$
        - 集成泛化误差 = 个体泛化误差的均值 - 个体分歧项的均值
        - $E = \bar{E} - \bar{A}$
- **多样性度量**
    - 多样性度量用于度量集成中个体分类器的多样性
    - 典型做法是考虑个体分类器的两两相似/不相似性
    - 不合度量, 相关系数, Q-统计量, $\kappa$-统计量
- **多样性增强**
    - **数据样本扰动**: 例如 Bagging 中的自助采样, AdaBoost 中的序列采样, 适合决策树, 神经网络这样的 **不稳定基学习器**
    - **输入属性扰动**: **随机子空间算法** 从初始属性中抽取若干属性子集, 再基于每个属性子集训练一个基学习器
    - **输出表示扰动**: 例如 ECOC 利用纠错输出码将多分类任务拆解成一系列二分类任务
    - **算法参数扰动**: **负相关法** 显式地通过正则化项来强制个体神经网络使用不同的参数


## 聚类

- 聚类能够作为一个单独过程, 用于寻找数据内在的分布结构, 也可以作为分类或其他学习任务的前驱过程
- **性能度量**
    - 聚类性能度量亦称聚类 **有效性指标**
    - 聚类结果 **簇内相似度高** 且 **簇间相似度** 低
    - 聚类性能度量大致分两类
        - **外部指标**: 将聚类结果于某个参考模型进行比较
            - Jaccard 系数, FM 指数, Rand 指数
        - **内部指标**: 直接考察聚类结果而不利用任何参考模型
            - DB 指数, Dunn 指数
- **距离计算**
    - 非负性, 同一性, 对称性, 直递性
    - 有序属性: 闵可夫斯基距离 ($L_p$ 范数)
    - 无序属性: VDM
- **原型聚类**
    - 原型聚类为基于原型的聚类, 能用一组原型来刻画
    - **学习向量化 LVQ**
        - LVQ 假设数据样本带有类别标记
        - 在每一轮迭代中, 算法随机选取一个有标记训练样本, 找出与之最近的原型向量, 再根据两个向量类别是否一致来对原型向量进行更新
        - 可以形成 Voronoi 剖分
    - **KMeans 算法**
        - 最小化平方误差
        - KMeans 使用了 hard EM
        - 相比于直接按照产生概率最大的最极大似然估计, EM 算法采用概率对数据集做加权再做极大似然估计. 前者称之为 hard EM, 后者称之为 soft EM
        - kmeans 是 GMM 的一种特例
        - 由于协方差为单位矩阵, 故 kmeans 聚类的形状是球形的, 而 GMM 是椭球型的
    - **高斯混合聚类 GMM**
        - GMM 不使用原型向量, 而是使用概率模型来表达聚类原型
        - GMM 由 $k$ 个混合高斯成分组成, $\alpha_i$ 是混合系数
        - EM 算法
            - E 步: 求样本 $j$ 属于每个高斯成分 $i$ 的后验概率 $\gamma_{ji}$
                - 使用贝叶斯公式计算
            - M 步: 更新模型参数 $\alpha_i, \mu_i, \Sigma_i$
                - 最大化对数似然, 使用 $\gamma_{ji}$ 来加权计算
- **密度聚类**
    - 基于密度的聚类, 假定聚类结构能通过样本分布的紧密程度决定
    - DBSCAN 基于一组领域参数来刻画样本分布的紧密程度
        - $\epsilon$-领域, 核心对象, 密度直达, 密度可达, 密度相连
- **层次聚类**
    - 层次聚类尝试在不同层次对数据集进行划分, 从而形成树的聚类结构
    - AGNES 自底向上


## 降维和度量学习

- **k 近邻学习**
    - 找出最近的 $k$ 个样本类别进行投票
    - 最近邻分类器虽然简单, 但是如果 **密度足够大**, 它的泛化错误率不超过贝叶斯最优分类器的错误率的两倍
- **维数灾难**
    - 在高维情形下出现的数据样本稀疏, 距离计算困难等问题
    - 一个重要的缓解手段: 降维, 亦称维数约简
    - **多维缩放 MDS**
- **主成分分析 (Principal Component Analysis, PCA)**:
    - 主成分分析要求超平面有下列性质
        - **最近重构性**: 样本点到这个超平面的距离都足够近;
        - **最大可分性**: 样本点在这个超平面上的投影能尽可能分开.
    - **算法**
        - 对所有样本进行中心化, 得到新的 $X$
        - 计算样本的协方差矩阵 $XX^{T}$ 或 $\displaystyle \frac{1}{m}XX^{T}$ 或 $\displaystyle \frac{1}{m - 1}XX^{T}$ (正确地来说应该使用最后的这一个, 如果是行向量则是 $X^{T}X$)
        - 对协方差矩阵进行特征值分解
        - 取最大的 $d'$ 个特征值所对应的特征向量组成投影矩阵 $W = (w_1, w_2, \ldots, w_{d'})$
        - 低维表示可以简洁地写为 $Y = W^{T}X$ (行向量为 $Y = XW$)
        - 重构可以写为 $\hat{X} = \bar{X} + WW^{T}X$ (行向量为 $\hat{X} = \bar{X} + XWW^{T}$)
    - $d'$ 可以事先指定, 也可以根据降维后特征值之和与降维前特征值之和之比来判断, 一般只需要大于 0.9 左右即可
        - 舍弃这部分信息可以使样本的采样密度增大, 这是降维的重要动机
        - 这部分信息往往跟噪音有关, 舍弃这部分信息能在一定程度上起到降噪作用
    - 从最近重构性出发
        - $\omega_i$ 是标准正交基, 投影分量 $z_{ij} = w_j^{T}x_i$
        - 使用最小二乘法优化重构误差
        - $\displaystyle \sum_{i=1}^{m}\left\| \sum_{j=1}^{d'}z_{ij}w_j - x_i \right\|^{2} = \sum_{i=1}^{m}z_i^{T}z_i - 2\sum_{i=1}^{m}z_i^{T}W^{T}x_i + \operatorname{const} \propto -\operatorname{tr}(W^{T}XX^{T}W)$
    - 从最大可分性出发
        - 样本点在超平面上的投影 $\bm{W}^{\mathrm{T}}\bm{x}_i$ 的方差 $\bm{W}^{\mathrm{T}}\bm{x}_i\bm{x}_i^{\mathrm{T}}\bm{W}$ 应该最大化, 因此
        $$
        \begin{aligned}
        \max &\quad \operatorname{tr}(\bm{W}^{\mathrm{T}}\bm{X}\bm{X}^{\mathrm{T}}\bm{W})  \\
        \text{s.t.} &\quad \bm{W}^{\mathrm{T}}\bm{W} = \bm{I}  \\
        \end{aligned}
        $$
        - 因此有 $\bm{X}\bm{X}^{\mathrm{T}}\bm{W} = \lambda \bm{W}$.
    - PCA 也可以看作逐一选取方差最大方向, 即先选取 $\sum_{i}x_i x_i^{T}$ 做特征值分解取最大特征值对应特征向量, 再对 $\sum_{i}x_i x_i^{T} - \lambda_1 w_1 w_1^{T}$ 做特征值分解取最大特征值对应特征向量
        - 由 $W$ 各分量正交, 以及 **谱分解** $\sum_{i=1}^{m}x_i x_i^{T} = \sum_{j=1}^{d}\lambda_j w_j w_j^{T}$ 可知与直接选 $d'$ 个最大 $d'$ 个特征值等价
        - **PCA 是最佳的仿射变换拟合**
    - 为什么 PCA 需要进行中心化?
        - 从线性变换的本质来说, PCA 就是在线性空间做一个旋转, 必须保证原本空间里的点是以原点为中心分布
        - 这也是由 PCA 的定义决定的, 从协方差矩阵的定义来看, 协方差矩阵中的协方差是要先减去期望后再进行二乘的
    - 特征值和特征分解:
        - 特征值和特征向量 $Ax = \lambda x$ 或 $(A - \lambda I) x = 0$
        - 特征方程 $\det(A - \lambda I) = 0$
    - 实对称矩阵性质:
        - 实对称矩阵的特征值都是实数
        - 实对称矩阵的属于不同特征值的特征向量相互正交
        - **任何实对称矩阵正交相似于对角阵, 即存在正交阵 $Q$, 使得 $Q^{T}AQ$ 为对角阵**
        - 谱分解: $A = \lambda_1 q_1q_1^{T} + \cdots + \lambda_n q_n q_n^{T}$
        - 实对称矩阵 $A$ 的对角线元素 $a_{ii} \le \lambda_{\max}$
        - 实对称矩阵的正特征值数与正主元数相同
    - 半正定矩阵
        - 对任意非零列向量 $x$ 有二次型 $x^{T}Ax \ge 0$
        - 半正定矩阵行列式非负
        - 半正定矩阵所有主子式非负
        - 半正定矩阵所有特征值非负
        - 存在实矩阵 $C$ 使得 $A = C^{T}C$
- 核化线性降维
    - 非线性降维的常用方式是基于核技巧对线性降维方法进行核化, 例如 **核主成分分析 KPCA**
    - 在高维特征空间进行 PCA: $\displaystyle (\sum_{i=1}^{m}\phi(x_i)\phi(x_i)^{T})W = \lambda W$
        - $z_i = \phi(x_i)$
        - $\displaystyle W = \sum_{i=1}^{m}\phi(x_i)\alpha_i, \alpha_i = \frac{1}{\lambda} \phi(x_i)^{T}W$
    - 引入核函数 $\kappa(x_i, x_j) = \phi(x_i)^{T}\phi(x_j)$ 则化简为 $KA = \lambda A$
    - 投影后样本的第 $j$ 维空间为 $z_j = w_j^{T}\phi(x) = \sum_{i=1}^{m}\alpha_{i}^{j}\kappa(x_i, x)$
- 流形学习
    - **等度量映射 Isomap**: 高维空间的直线距离在低维嵌入流形上是不可达的
        - 将两点之间测地线距离, 转变为计算近邻连接图上两点之间的最短路径问题
        - 可以采用 Dijkstta 算法或者 Floyd 算法, 然后使用 MDS 方法来获得
    - 局部线性嵌入
        - 与 Isomap 试图保持近邻样本之间的距离不同, 局部线性嵌入试图保持领域样本之间的线性关系
- **度量学习**
    - 降维主要目的是找到一个合适的低维空间, 实际上对应了一个距离度量
    - 具体尝试直接学习出一个合适的距离度量
    - **马氏距离**: $\operatorname{dist}_{mah}^{2}(x_i, x_j) = (x_i - x_j)^{T}M(x_i - x_j) = \left\| x_i - x_j \right\|_{M}^{2}$
        - 其中 $M$ 是一个半正定矩阵, 也即必有正交基 $P$ 使得 $M = PP^{T}$
    - 对 $M$ 学习要设定目标, 我们希望提高近邻分类器的性能
    - 还能引入领域知识, 例如必连和勿连
